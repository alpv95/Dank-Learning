{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import things needed for Tensorflow and CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __builtin__ import any as b_any\n",
    "\n",
    "import math\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import configuration\n",
    "import inference_wrapper\n",
    "import sys\n",
    "sys.path.insert(0, 'im2txt/inference_utils')\n",
    "sys.path.insert(0, 'im2txt/ops')\n",
    "import caption_generator\n",
    "import image_processing\n",
    "import vocabulary\n",
    "\n",
    "import urllib, os, sys, zipfile\n",
    "from os.path import dirname\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "from tensorflow.python.tools.freeze_graph import freeze_graph\n",
    "from tensorflow.python.tools import strip_unused_lib\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.platform import gfile\n",
    "import tfcoreml\n",
    "import configuration\n",
    "from coremltools.proto import NeuralNetwork_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "# Turn on debugging on error\n",
    "%pdb off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the models\n",
    "\n",
    "Create the Tensorflow model and strip all unused nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = './trainlogIncNEW/model.ckpt-1000000'\n",
    "pre_frozen_model_file = './frozen_model_textgenCUSTOM.pb'\n",
    "frozen_model_file = './frozen_model_textgenCUSTOM.pb'\n",
    "\n",
    "# Which nodes we want to input for the network\n",
    "# Use ['image_feed'] for just Memeception\n",
    "input_node_names = ['seq_embeddings','lstm/state_feed']\n",
    "\n",
    "# Which nodes we want to output from the network\n",
    "# Use ['lstm/initial_state'] for just Memeception\n",
    "output_node_names = ['softmax_T','lstm/state']\n",
    "\n",
    "# Set the depth of the beam search\n",
    "beam_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n",
      "About to decide if splitting\n",
      "FIRST (1, 2048)\n",
      "{'num_or_size_splits': 4, 'value': <tf.Tensor 'lstm/basic_lstm_cell/BiasAdd:0' shape=(1, 2048) dtype=float32>, 'axis': 1}\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_2:0\", shape=(1, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_1:0' shape=(1, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_2:0' shape=(1, 512) dtype=float32>)\n",
      "About to decide if splitting\n",
      "SECOND (2, 2048)\n",
      "{'num_or_size_splits': 4, 'value': <tf.Tensor 'lstm/basic_lstm_cell/BiasAdd_1:0' shape=(2, 2048) dtype=float32>, 'axis': 1}\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_3:0' shape=(1, 2, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_5:0' shape=(1, 2, 512) dtype=float32>)\n",
      "lstm_outputs Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "state_output LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_3:0' shape=(1, 2, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_5:0' shape=(1, 2, 512) dtype=float32>)\n",
      "BUILDING DENSE\n",
      "MATMUL(TENSORDOT) w/out SPLITTING\n"
     ]
    }
   ],
   "source": [
    "# Build the inference graph.\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model = inference_wrapper.InferenceWrapper()\n",
    "    restore_fn = model.build_graph_from_config(configuration.ModelConfig(),\n",
    "                                               checkpoint_file)\n",
    "g.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47091952"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the graph\n",
    "\n",
    "tf_model_path = './log/pre_graph_textgenCUSTOM.pb'\n",
    "tf.train.write_graph(\n",
    "    g,\n",
    "    './log',\n",
    "    'pre_graph_textgenCUSTOM.pb',\n",
    "    as_text=False,\n",
    ")\n",
    "\n",
    "with open(tf_model_path, 'rb') as f:\n",
    "    serialized = f.read()\n",
    "tf.reset_default_graph()\n",
    "original_gdef = tf.GraphDef()\n",
    "original_gdef.ParseFromString(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip unused graph elements and serialize the output to file\n",
    "\n",
    "gdef = strip_unused_lib.strip_unused(\n",
    "        input_graph_def = original_gdef,\n",
    "        input_node_names = input_node_names,\n",
    "        output_node_names = output_node_names,\n",
    "        placeholder_type_enum = dtypes.float32.as_datatype_enum)\n",
    "# Save it to an output file\n",
    "with gfile.GFile(pre_frozen_model_file, 'wb') as f:\n",
    "    f.write(gdef.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trainlogIncNEW/model.ckpt-1000000\n",
      "INFO:tensorflow:Froze 4 variables.\n",
      "Converted 4 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Freeze the graph with checkpoint data inside\n",
    "\n",
    "freeze_graph(input_graph=pre_frozen_model_file,\n",
    "             input_saver='',\n",
    "             input_binary=True,\n",
    "             input_checkpoint=checkpoint_file,\n",
    "             output_node_names=','.join(output_node_names),\n",
    "             restore_op_name='save/restore_all',\n",
    "             filename_tensor_name='save/Const:0',\n",
    "             output_graph=frozen_model_file,\n",
    "             clear_devices=True,\n",
    "             initializer_nodes='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the model\n",
    "\n",
    "Check that it is producing legit captions for *One does not simply*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: vocab4.txt\n",
      "INFO:tensorflow:Created vocabulary with 38521 words\n"
     ]
    }
   ],
   "source": [
    "# Configure the model and load the vocab\n",
    "\n",
    "config = configuration.ModelConfig()\n",
    "\n",
    "vocab_file ='vocab4.txt'\n",
    "vocab = vocabulary.Vocabulary(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt\n",
      "the god of humanity is a sin\n",
      "the god of humanity is a sin lol .\n",
      "i just met you , and this is crazy but i'm the doctor , don't punish me\n",
      "create memes on the internet with the creator\n",
      "create memes on the internet with the memes of the day is nothing\n",
      "we need to be a feminist feminist\n",
      "we need to be a feminist unless you disagree\n",
      "is the best dm in the world ? let the bodies go\n",
      "is the best dm in the world ? let the bodies go up\n",
      "this is my plan\n",
      "this is . . .\n",
      "if you think the bible is going to hell you don't think you are an atheist\n",
      "if you think the bible is going to hell you don't think you are a good time\n",
      "why do you kill people they don't know the difference between them and kill them\n",
      "has a shot of the world believes in the middle of the world\n",
      "has a shot of the world believes in the middle east\n",
      "doesn't believe in god of the god of god\n",
      "doesn't believe in god of the god of god loves satan\n"
     ]
    }
   ],
   "source": [
    "# Generate captions on a hard-coded image\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "  restore_fn(sess)\n",
    "  generator = caption_generator.CaptionGenerator(\n",
    "      model, vocab, beam_size=beam_size)\n",
    "  for i,filename in enumerate(['memes/advice-god.jpg']):\n",
    "    with tf.gfile.GFile(filename, \"rb\") as f:\n",
    "      image = Image.open(f)\n",
    "      image = ((np.array(image.resize((299,299)))/255.0)-0.5)*2.0\n",
    "    for k in range(10):\n",
    "      captions = generator.beam_search(sess, image)    \n",
    "      for i, caption in enumerate(captions):\n",
    "        sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "        sentence = \" \".join(sentence)\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model to CoreML\n",
    "\n",
    "Specify output variables from the graph to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic shapes\n",
    "# If using Memeception, add 'image_feed:0': [299, 299, 3]\n",
    "input_tensor_shapes = {\n",
    "    'seq_embeddings:0': [1, beam_size, 300],\n",
    "    'lstm/state_feed:0': [1, beam_size, 1024],\n",
    "}\n",
    "\n",
    "coreml_model_file = './Textgen_CUSTOM.mlmodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor_names = [node + ':0' for node in output_node_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightLSTM = np.loadtxt('weightLSTM')\n",
    "weightFully = np.loadtxt('weightFully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 40 tensors. Executing graph to determine shapes. \n",
      "Automatic shape interpretation succeeded for input blob lstm/state_feed:0\n",
      "1/148: Analysing op name: seq_embeddings ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "2/148: Analysing op name: lstm/basic_lstm_cell/kernel ( type:  Const )\n",
      "3/148: Analysing op name: lstm/basic_lstm_cell/kernel/read ( type:  Identity )\n",
      "4/148: Analysing op name: lstm/basic_lstm_cell/bias ( type:  Const )\n",
      "5/148: Analysing op name: lstm/basic_lstm_cell/bias/read ( type:  Identity )\n",
      "6/148: Analysing op name: lstm/state_feed ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "7/148: Analysing op name: lstm/ExpandDims/dim ( type:  Const )\n",
      "8/148: Analysing op name: lstm/ExpandDims ( type:  ExpandDims )\n",
      "9/148: Analysing op name: lstm/split/split_dim ( type:  Const )\n",
      "10/148: Analysing op name: lstm/split ( type:  Split )\n",
      "11/148: Analysing op name: lstm/Squeeze ( type:  Squeeze )\n",
      "12/148: Analysing op name: lstm/Squeeze_1 ( type:  Squeeze )\n",
      "13/148: Analysing op name: lstm/basic_lstm_cell/concat_1/axis ( type:  Const )\n",
      "14/148: Analysing op name: lstm/basic_lstm_cell/concat_1 ( type:  ConcatV2 )\n",
      "15/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_8 ( type:  Squeeze )\n",
      "16/148: Analysing op name: lstm/basic_lstm_cell/transpose/Rank ( type:  Rank )\n",
      "17/148: Analysing op name: lstm/basic_lstm_cell/transpose/sub/y ( type:  Const )\n",
      "18/148: Analysing op name: lstm/basic_lstm_cell/transpose/sub ( type:  Sub )\n",
      "19/148: Analysing op name: lstm/basic_lstm_cell/transpose/Range/start ( type:  Const )\n",
      "20/148: Analysing op name: lstm/basic_lstm_cell/transpose/Range/delta ( type:  Const )\n",
      "21/148: Analysing op name: lstm/basic_lstm_cell/transpose/Range ( type:  Range )\n",
      "22/148: Analysing op name: lstm/basic_lstm_cell/transpose/sub_1 ( type:  Sub )\n",
      "23/148: Analysing op name: lstm/basic_lstm_cell/transpose ( type:  Transpose )\n",
      "24/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_2/dim ( type:  Const )\n",
      "25/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_2 ( type:  ExpandDims )\n",
      "26/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_3/dim ( type:  Const )\n",
      "27/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_3 ( type:  ExpandDims )\n",
      "28/148: Analysing op name: lstm/basic_lstm_cell/split_1/split_dim ( type:  Const )\n",
      "29/148: Analysing op name: lstm/basic_lstm_cell/split_1 ( type:  Split )\n",
      "30/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_9 ( type:  Squeeze )\n",
      "31/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_10 ( type:  Squeeze )\n",
      "32/148: Analysing op name: lstm/basic_lstm_cell/transpose_1/Rank ( type:  Rank )\n",
      "33/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_11 ( type:  Squeeze )\n",
      "34/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_12 ( type:  Squeeze )\n",
      "35/148: Analysing op name: lstm/basic_lstm_cell/transpose_2/Rank ( type:  Rank )\n",
      "36/148: Analysing op name: lstm/basic_lstm_cell/transpose_1/sub/y ( type:  Const )\n",
      "37/148: Analysing op name: lstm/basic_lstm_cell/transpose_1/sub ( type:  Sub )\n",
      "38/148: Analysing op name: lstm/basic_lstm_cell/transpose_1/Range/start ( type:  Const )\n",
      "39/148: Analysing op name: lstm/basic_lstm_cell/transpose_1/Range/delta ( type:  Const )\n",
      "40/148: Analysing op name: lstm/basic_lstm_cell/transpose_1/Range ( type:  Range )\n",
      "41/148: Analysing op name: lstm/basic_lstm_cell/transpose_1/sub_1 ( type:  Sub )\n",
      "42/148: Analysing op name: lstm/basic_lstm_cell/transpose_1 ( type:  Transpose )\n",
      "43/148: Analysing op name: lstm/basic_lstm_cell/MatMul_1 ( type:  MatMul )\n",
      "44/148: Analysing op name: lstm/basic_lstm_cell/transpose_2/sub/y ( type:  Const )\n",
      "45/148: Analysing op name: lstm/basic_lstm_cell/transpose_2/sub ( type:  Sub )\n",
      "46/148: Analysing op name: lstm/basic_lstm_cell/transpose_2/Range/start ( type:  Const )\n",
      "47/148: Analysing op name: lstm/basic_lstm_cell/transpose_2/Range/delta ( type:  Const )\n",
      "48/148: Analysing op name: lstm/basic_lstm_cell/transpose_2/Range ( type:  Range )\n",
      "49/148: Analysing op name: lstm/basic_lstm_cell/transpose_2/sub_1 ( type:  Sub )\n",
      "50/148: Analysing op name: lstm/basic_lstm_cell/transpose_2 ( type:  Transpose )\n",
      "51/148: Analysing op name: lstm/basic_lstm_cell/MatMul_2 ( type:  MatMul )\n",
      "52/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_4/dim ( type:  Const )\n",
      "53/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_4 ( type:  ExpandDims )\n",
      "54/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_5/dim ( type:  Const )\n",
      "55/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_5 ( type:  ExpandDims )\n",
      "56/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_6/dim ( type:  Const )\n",
      "57/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_6 ( type:  ExpandDims )\n",
      "58/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_7/dim ( type:  Const )\n",
      "59/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_7 ( type:  ExpandDims )\n",
      "60/148: Analysing op name: lstm/basic_lstm_cell/concat_2/axis ( type:  Const )\n",
      "61/148: Analysing op name: lstm/basic_lstm_cell/concat_2 ( type:  ConcatV2 )\n",
      "62/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_13 ( type:  Squeeze )\n",
      "63/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_14 ( type:  Squeeze )\n",
      "64/148: Analysing op name: lstm/basic_lstm_cell/BiasAdd_1 ( type:  BiasAdd )\n",
      "65/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_8/dim ( type:  Const )\n",
      "66/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_8 ( type:  ExpandDims )\n",
      "67/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_9/dim ( type:  Const )\n",
      "68/148: Analysing op name: lstm/basic_lstm_cell/ExpandDims_9 ( type:  ExpandDims )\n",
      "69/148: Analysing op name: lstm/basic_lstm_cell/split_2/split_dim ( type:  Const )\n",
      "70/148: Analysing op name: lstm/basic_lstm_cell/split_2 ( type:  Split )\n",
      "71/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_15 ( type:  Squeeze )\n",
      "72/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_16 ( type:  Squeeze )\n",
      "73/148: Analysing op name: lstm/basic_lstm_cell/Sigmoid_4 ( type:  Sigmoid )\n",
      "74/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_17 ( type:  Squeeze )\n",
      "75/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_18 ( type:  Squeeze )\n",
      "76/148: Analysing op name: lstm/basic_lstm_cell/Tanh_2 ( type:  Tanh )\n",
      "77/148: Analysing op name: lstm/basic_lstm_cell/Mul_4 ( type:  Mul )\n",
      "78/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_19 ( type:  Squeeze )\n",
      "79/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_20 ( type:  Squeeze )\n",
      "80/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_21 ( type:  Squeeze )\n",
      "81/148: Analysing op name: lstm/basic_lstm_cell/Squeeze_22 ( type:  Squeeze )\n",
      "82/148: Analysing op name: lstm/basic_lstm_cell/Sigmoid_5 ( type:  Sigmoid )\n",
      "83/148: Analysing op name: lstm/basic_lstm_cell/Const_4 ( type:  Const )\n",
      "84/148: Analysing op name: lstm/basic_lstm_cell/Add_2 ( type:  Add )\n",
      "85/148: Analysing op name: lstm/basic_lstm_cell/Sigmoid_3 ( type:  Sigmoid )\n",
      "86/148: Analysing op name: lstm/basic_lstm_cell/Mul_3 ( type:  Mul )\n",
      "87/148: Analysing op name: lstm/basic_lstm_cell/Add_3 ( type:  Add )\n",
      "88/148: Analysing op name: lstm/basic_lstm_cell/Tanh_3 ( type:  Tanh )\n",
      "89/148: Analysing op name: lstm/basic_lstm_cell/Mul_5 ( type:  Mul )\n",
      "90/148: Analysing op name: logits/Squeeze ( type:  Squeeze )\n",
      "91/148: Analysing op name: logits/transpose/Rank ( type:  Rank )\n",
      "92/148: Analysing op name: lstm/state/axis ( type:  Const )\n",
      "93/148: Analysing op name: lstm/state ( type:  ConcatV2 )\n",
      "94/148: Analysing op name: logits/weights ( type:  Const )\n",
      "95/148: Analysing op name: logits/weights/read ( type:  Identity )\n",
      "96/148: Analysing op name: logits/biases ( type:  Const )\n",
      "97/148: Analysing op name: logits/biases/read ( type:  Identity )\n",
      "98/148: Analysing op name: logits/transpose/sub/y ( type:  Const )\n",
      "99/148: Analysing op name: logits/transpose/sub ( type:  Sub )\n",
      "100/148: Analysing op name: logits/transpose/Range/start ( type:  Const )\n",
      "101/148: Analysing op name: logits/transpose/Range/delta ( type:  Const )\n",
      "102/148: Analysing op name: logits/transpose/Range ( type:  Range )\n",
      "103/148: Analysing op name: logits/transpose/sub_1 ( type:  Sub )\n",
      "104/148: Analysing op name: logits/transpose ( type:  Transpose )\n",
      "105/148: Analysing op name: logits/ExpandDims/dim ( type:  Const )\n",
      "106/148: Analysing op name: logits/ExpandDims ( type:  ExpandDims )\n",
      "107/148: Analysing op name: logits/ExpandDims_1/dim ( type:  Const )\n",
      "108/148: Analysing op name: logits/ExpandDims_1 ( type:  ExpandDims )\n",
      "109/148: Analysing op name: logits/split/split_dim ( type:  Const )\n",
      "110/148: Analysing op name: logits/split ( type:  Split )\n",
      "111/148: Analysing op name: logits/Squeeze_1 ( type:  Squeeze )\n",
      "112/148: Analysing op name: logits/Squeeze_2 ( type:  Squeeze )\n",
      "113/148: Analysing op name: logits/transpose_1/Rank ( type:  Rank )\n",
      "114/148: Analysing op name: logits/Squeeze_3 ( type:  Squeeze )\n",
      "115/148: Analysing op name: logits/Squeeze_4 ( type:  Squeeze )\n",
      "116/148: Analysing op name: logits/transpose_2/Rank ( type:  Rank )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/148: Analysing op name: logits/transpose_1/sub/y ( type:  Const )\n",
      "118/148: Analysing op name: logits/transpose_1/sub ( type:  Sub )\n",
      "119/148: Analysing op name: logits/transpose_1/Range/start ( type:  Const )\n",
      "120/148: Analysing op name: logits/transpose_1/Range/delta ( type:  Const )\n",
      "121/148: Analysing op name: logits/transpose_1/Range ( type:  Range )\n",
      "122/148: Analysing op name: logits/transpose_1/sub_1 ( type:  Sub )\n",
      "123/148: Analysing op name: logits/transpose_1 ( type:  Transpose )\n",
      "124/148: Analysing op name: logits/MatMul ( type:  MatMul )\n",
      "125/148: Analysing op name: logits/transpose_2/sub/y ( type:  Const )\n",
      "126/148: Analysing op name: logits/transpose_2/sub ( type:  Sub )\n",
      "127/148: Analysing op name: logits/transpose_2/Range/start ( type:  Const )\n",
      "128/148: Analysing op name: logits/transpose_2/Range/delta ( type:  Const )\n",
      "129/148: Analysing op name: logits/transpose_2/Range ( type:  Range )\n",
      "130/148: Analysing op name: logits/transpose_2/sub_1 ( type:  Sub )\n",
      "131/148: Analysing op name: logits/transpose_2 ( type:  Transpose )\n",
      "132/148: Analysing op name: logits/MatMul_1 ( type:  MatMul )\n",
      "133/148: Analysing op name: logits/ExpandDims_2/dim ( type:  Const )\n",
      "134/148: Analysing op name: logits/ExpandDims_2 ( type:  ExpandDims )\n",
      "135/148: Analysing op name: logits/ExpandDims_3/dim ( type:  Const )\n",
      "136/148: Analysing op name: logits/ExpandDims_3 ( type:  ExpandDims )\n",
      "137/148: Analysing op name: logits/ExpandDims_4/dim ( type:  Const )\n",
      "138/148: Analysing op name: logits/ExpandDims_4 ( type:  ExpandDims )\n",
      "139/148: Analysing op name: logits/ExpandDims_5/dim ( type:  Const )\n",
      "140/148: Analysing op name: logits/ExpandDims_5 ( type:  ExpandDims )\n",
      "141/148: Analysing op name: logits/concat/axis ( type:  Const )\n",
      "142/148: Analysing op name: logits/concat ( type:  ConcatV2 )\n",
      "143/148: Analysing op name: logits/Squeeze_5 ( type:  Squeeze )\n",
      "144/148: Analysing op name: logits/Squeeze_6 ( type:  Squeeze )\n",
      "145/148: Analysing op name: logits/BiasAdd ( type:  BiasAdd )\n",
      "146/148: Analysing op name: softmax ( type:  Softmax )\n",
      "147/148: Analysing op name: softmax_T/shape ( type:  Const )\n",
      "148/148: Analysing op name: softmax_T ( type:  Reshape )\n",
      "\n",
      " Core ML model generated. Saved at location: ./Textgen_CUSTOM.mlmodel \n",
      "\n",
      "Core ML input(s): \n",
      " [name: \"seq_embeddings__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 300\n",
      "    shape: 1\n",
      "    shape: 2\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      ", name: \"lstm__state_feed__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 1024\n",
      "    shape: 1\n",
      "    shape: 2\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "Core ML output(s): \n",
      " [name: \"lstm__state__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      ", name: \"softmax_T__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 1\n",
      "    shape: 2\n",
      "    shape: 38521\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "\n",
      "\n",
      "Custom layers have been added to the CoreML model corresponding to the following ops in the TF graph: \n",
      "1/2: op type: MatMul, op input names and shapes: [('lstm/basic_lstm_cell/Squeeze_8:0', [2, 812]), ('lstm/basic_lstm_cell/kernel/read:0', [812, 2048])], op output names and shapes: [('lstm/basic_lstm_cell/LSTMmatmul2:0', [2, 2048])]\n",
      "2/2: op type: MatMul, op input names and shapes: [('logits/Squeeze:0', [2, 512]), ('logits/weights/read:0', [512, 38521])], op output names and shapes: [('logits/Fullymatmul:0', [2, 38521])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convert_matmul(**kwargs):\n",
    "    # Only convert this Lambda layer if it is for our swish function.\n",
    "    tf_op = kwargs[\"op\"]\n",
    "    if tf_op.name == 'lstm/basic_lstm_cell/LSTMmatmul2':\n",
    "        W = weightLSTM\n",
    "        print('LSTM')\n",
    "    else:\n",
    "        W = weightFully\n",
    "        print('Fully')\n",
    "    coreml_nn_builder = kwargs[\"nn_builder\"]\n",
    "    constant_inputs = kwargs[\"constant_inputs\"]\n",
    "    \n",
    "    params = NeuralNetwork_pb2.CustomLayerParams()\n",
    "\n",
    "    # The name of the Swift or Obj-C class that implements this layer.\n",
    "    params.className = \"MatMul\"\n",
    "\n",
    "    # The desciption is shown in Xcode's mlmodel viewer.\n",
    "    params.description = \"A fancy new matmul\"\n",
    "    \n",
    "    #W = constant_inputs.get(tf_op.inputs[1].name,[0,100,0,0])\n",
    "    #print(tf_op.inputs[1])\n",
    "    #size = constant_inputs.get(tf_op.inputs[2].name, [0,0,0,0])\n",
    "    # add begin and size as two repeated weight fields\n",
    "    for i,weightvec in enumerate(W):\n",
    "        W_as_weights = params.weights.add()\n",
    "        W_as_weights.floatValue.extend(map(float, weightvec))\n",
    "    #print(W_as_weights)\n",
    "    #size_as_weights = params.weights.add()\n",
    "    #size_as_weights.floatValue.extend(map(float, size))\n",
    "    coreml_nn_builder.add_custom(name=tf_op.name,\n",
    "                                input_names=[tf_op.inputs[0].name],\n",
    "                                output_names=[tf_op.outputs[0].name],\n",
    "                                custom_proto_spec=params)\n",
    "\n",
    "    #return params\n",
    "\n",
    "\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file, \n",
    "        mlmodel_path=coreml_model_file, \n",
    "        input_name_shape_dict=input_tensor_shapes,\n",
    "        output_feature_names=output_tensor_names,\n",
    "        add_custom_layers=True,\n",
    "        custom_conversion_functions={ \"lstm/basic_lstm_cell/LSTMmatmul2\": convert_matmul, \"logits/Fullymatmul\": convert_matmul}\n",
    "        #custom_conversion_functions={ \"MatMuldlskfjslkfj\": convert_matmul}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "Run a predictable randomly seeded inputs through and see where the disparities are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_rand = np.random.rand(300)\n",
    "seq_embeddings_tf = np.array([[seq_rand, seq_rand]])\n",
    "seq_embeddings_ml = np.array([[[sr, sr]] for sr in seq_rand])\n",
    "\n",
    "state_rand = np.random.rand(1024)\n",
    "state_feed_tf = np.array([[state_rand, state_rand]])\n",
    "state_feed_ml = np.array([[[sr, sr]] for sr in state_rand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm__state__0\n",
      "(1, 1, 1024, 1, 2)\n",
      "[[[[[ 0.90899551  0.90899551]]\n",
      "\n",
      "   [[-0.05541002 -0.05541002]]\n",
      "\n",
      "   [[-0.65337896 -0.65337896]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 0.00151922  0.00151922]]\n",
      "\n",
      "   [[ 0.42886326  0.42886326]]\n",
      "\n",
      "   [[ 0.5491575   0.5491575 ]]]]]\n",
      "softmax_T__0\n",
      "(1, 2, 38521)\n",
      "[[[8.12411236e-06 5.30541362e-03 1.70792900e-02 ... 1.64068956e-02\n",
      "   4.17694446e-06 4.88249101e-02]\n",
      "  [8.12411236e-06 5.30541362e-03 1.70792900e-02 ... 1.64068956e-02\n",
      "   4.17694446e-06 4.88249101e-02]]]\n"
     ]
    }
   ],
   "source": [
    "coreml_inputs = {\n",
    "    'seq_embeddings__0': seq_embeddings_ml,\n",
    "    'lstm__state_feed__0': state_feed_ml,\n",
    "}\n",
    "coreml_output = coreml_model.predict(coreml_inputs, useCPUOnly=True)\n",
    "# print(coreml_output['lstm__state__0'].shape)\n",
    "# print(coreml_output['softmax__0'].shape)\n",
    "# print(coreml_output['softmax__0'].reshape(38521, 1, 2))\n",
    "# print(coreml_output)\n",
    "def print_ml(ml):\n",
    "    for key in sorted(ml.keys()):\n",
    "        print(key)\n",
    "        print(ml[key].shape)\n",
    "        print(ml[key])\n",
    "print_ml(coreml_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt\n",
      "lstm/state:0\n",
      "(1, 2, 1024)\n",
      "[[[ 0.9089954  -0.05541002 -0.65337884 ...  0.00151924  0.4288631\n",
      "    0.5491576 ]\n",
      "  [ 0.9089954  -0.05541002 -0.65337884 ...  0.00151924  0.4288631\n",
      "    0.5491576 ]]]\n",
      "softmax:0\n",
      "(2, 38521)\n",
      "[[8.1241205e-06 5.3054192e-03 1.7079309e-02 ... 1.6406905e-02\n",
      "  4.1769486e-06 4.8824962e-02]\n",
      " [8.1241205e-06 5.3054192e-03 1.7079309e-02 ... 1.6406905e-02\n",
      "  4.1769486e-06 4.8824962e-02]]\n",
      "softmax_T:0\n",
      "(1, 2, 38521, 1)\n",
      "[[[[8.1241205e-06]\n",
      "   [5.3054192e-03]\n",
      "   [1.7079309e-02]\n",
      "   ...\n",
      "   [1.6406905e-02]\n",
      "   [4.1769486e-06]\n",
      "   [4.8824962e-02]]\n",
      "\n",
      "  [[8.1241205e-06]\n",
      "   [5.3054192e-03]\n",
      "   [1.7079309e-02]\n",
      "   ...\n",
      "   [1.6406905e-02]\n",
      "   [4.1769486e-06]\n",
      "   [4.8824962e-02]]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    # Load the model from checkpoint.\n",
    "    restore_fn(sess)\n",
    "    input_names = ['lstm/state:0', 'softmax:0', 'softmax_T:0']\n",
    "    output_values = sess.run(\n",
    "        fetches=input_names,\n",
    "        feed_dict={\n",
    "            #\"input_feed:0\": input_feed,\n",
    "            \"lstm/state_feed:0\": state_feed_tf,\n",
    "            \"seq_embeddings:0\": seq_embeddings_tf,\n",
    "            #\"seq_embedding/embedding_map:0\": self.embedding_map\n",
    "        })\n",
    "    for (index, value) in sorted(enumerate(input_names), key=lambda x: x[1]):\n",
    "        print(value)\n",
    "        print(output_values[index].shape)\n",
    "        print(output_values[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(np.random.rand(1, 20), np.random.rand(20, 45)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(1, 2, 812)[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
