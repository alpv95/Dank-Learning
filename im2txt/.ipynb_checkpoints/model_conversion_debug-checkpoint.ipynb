{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import things needed for Tensorflow and CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __builtin__ import any as b_any\n",
    "\n",
    "import math\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import configuration\n",
    "import inference_wrapper\n",
    "import sys\n",
    "sys.path.insert(0, 'im2txt/inference_utils')\n",
    "sys.path.insert(0, 'im2txt/ops')\n",
    "import caption_generator\n",
    "import image_processing\n",
    "import vocabulary\n",
    "\n",
    "import urllib, os, sys, zipfile\n",
    "from os.path import dirname\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "from tensorflow.python.tools.freeze_graph import freeze_graph\n",
    "from tensorflow.python.tools import strip_unused_lib\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.platform import gfile\n",
    "import tfcoreml\n",
    "import configuration\n",
    "from coremltools.proto import NeuralNetwork_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "# Turn on debugging on error\n",
    "%pdb on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the models\n",
    "\n",
    "Create the Tensorflow model and strip all unused nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = './trainlogIncNEW/model.ckpt'\n",
    "pre_frozen_model_file = './frozen_model_textgenNEW.pb'\n",
    "frozen_model_file = './frozen_model_textgenNEW.pb'\n",
    "\n",
    "# Which nodes we want to input for the network\n",
    "# Use ['image_feed'] for just Memeception\n",
    "input_node_names = ['seq_embeddings','lstm/state_feed']\n",
    "\n",
    "# Which nodes we want to output from the network\n",
    "# Use ['lstm/initial_state'] for just Memeception\n",
    "output_node_names = ['softmax_T','lstm/state']\n",
    "\n",
    "# Set the depth of the beam search\n",
    "beam_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n",
      "About to decide if splitting\n",
      "splitting mat mul\n",
      "(1, 812)\n",
      "Tensor(\"lstm/basic_lstm_cell/concat:0\", shape=(1, 812), dtype=float32)\n",
      "(812, 2048)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "___\n",
      "FIRST (1, 2048)\n",
      "{'num_or_size_splits': 4, 'value': <tf.Tensor 'lstm/basic_lstm_cell/BiasAdd:0' shape=(1, 2048) dtype=float32>, 'axis': 1}\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_2:0\", shape=(1, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_1:0' shape=(1, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_2:0' shape=(1, 512) dtype=float32>)\n",
      "About to decide if splitting\n",
      "splitting mat mul\n",
      "(2, 812)\n",
      "Tensor(\"lstm/basic_lstm_cell/Squeeze_8:0\", shape=(2, 812), dtype=float32)\n",
      "(812, 2048)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "___\n",
      "('NUMSPLITS', 2)\n",
      "{'num_or_size_splits': 2, 'value': <tf.Tensor 'lstm/basic_lstm_cell/transpose:0' shape=(812, 2) dtype=float32>, 'axis': 1}\n",
      "2\n",
      "(1, 812)\n",
      "MATMUL###\n",
      "(1, 812)\n",
      "Tensor(\"lstm/basic_lstm_cell/transpose_1:0\", shape=(1, 812), dtype=float32)\n",
      "(812, 2048)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "###\n",
      "MATMUL###\n",
      "(1, 812)\n",
      "Tensor(\"lstm/basic_lstm_cell/transpose_2:0\", shape=(1, 812), dtype=float32)\n",
      "(812, 2048)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "###\n",
      "('MULS', [<tf.Tensor 'lstm/basic_lstm_cell/MatMul_1:0' shape=(1, 2048) dtype=float32>, <tf.Tensor 'lstm/basic_lstm_cell/MatMul_2:0' shape=(1, 2048) dtype=float32>])\n",
      "SECOND (2, 2048)\n",
      "{'num_or_size_splits': 4, 'value': <tf.Tensor 'lstm/basic_lstm_cell/BiasAdd_1:0' shape=(2, 2048) dtype=float32>, 'axis': 1}\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_3:0' shape=(1, 2, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_5:0' shape=(1, 2, 512) dtype=float32>)\n",
      "lstm_outputs Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "state_output LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_3:0' shape=(1, 2, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_5:0' shape=(1, 2, 512) dtype=float32>)\n",
      "BUILDING DENSE\n",
      "MATMUL(TENSORDOT) w/out SPLITTING\n",
      "splitting mat mul\n",
      "(1, 2, 512)\n",
      "Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "(512, 38521)\n",
      "<tf.Variable 'logits/weights:0' shape=(512, 38521) dtype=float32_ref>\n",
      "___\n",
      "('NUMSPLITS', 2)\n",
      "{'num_or_size_splits': 2, 'value': <tf.Tensor 'logits/transpose:0' shape=(512, 2) dtype=float32>, 'axis': 1}\n",
      "2\n",
      "(1, 512)\n",
      "MATMUL###\n",
      "(1, 512)\n",
      "Tensor(\"logits/transpose_1:0\", shape=(1, 512), dtype=float32)\n",
      "(512, 38521)\n",
      "<tf.Variable 'logits/weights:0' shape=(512, 38521) dtype=float32_ref>\n",
      "###\n",
      "MATMUL###\n",
      "(1, 512)\n",
      "Tensor(\"logits/transpose_2:0\", shape=(1, 512), dtype=float32)\n",
      "(512, 38521)\n",
      "<tf.Variable 'logits/weights:0' shape=(512, 38521) dtype=float32_ref>\n",
      "###\n",
      "('MULS', [<tf.Tensor 'logits/MatMul:0' shape=(1, 38521) dtype=float32>, <tf.Tensor 'logits/MatMul_1:0' shape=(1, 38521) dtype=float32>])\n"
     ]
    }
   ],
   "source": [
    "# Build the inference graph.\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model = inference_wrapper.InferenceWrapper()\n",
    "    restore_fn = model.build_graph_from_config(configuration.ModelConfig(),\n",
    "                                               checkpoint_file)\n",
    "g.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47092335"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the graph\n",
    "\n",
    "tf_model_path = './log/pre_graph_textgenNEW.pb'\n",
    "tf.train.write_graph(\n",
    "    g,\n",
    "    './log',\n",
    "    'pre_graph_textgenNEW.pb',\n",
    "    as_text=False,\n",
    ")\n",
    "\n",
    "with open(tf_model_path, 'rb') as f:\n",
    "    serialized = f.read()\n",
    "tf.reset_default_graph()\n",
    "original_gdef = tf.GraphDef()\n",
    "original_gdef.ParseFromString(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip unused graph elements and serialize the output to file\n",
    "\n",
    "gdef = strip_unused_lib.strip_unused(\n",
    "        input_graph_def = original_gdef,\n",
    "        input_node_names = input_node_names,\n",
    "        output_node_names = output_node_names,\n",
    "        placeholder_type_enum = dtypes.float32.as_datatype_enum)\n",
    "# Save it to an output file\n",
    "with gfile.GFile(pre_frozen_model_file, 'wb') as f:\n",
    "    f.write(gdef.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Froze 4 variables.\n",
      "Converted 4 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Freeze the graph with checkpoint data inside\n",
    "\n",
    "freeze_graph(input_graph=pre_frozen_model_file,\n",
    "             input_saver='',\n",
    "             input_binary=True,\n",
    "             input_checkpoint=checkpoint_file,\n",
    "             output_node_names=','.join(output_node_names),\n",
    "             restore_op_name='save/restore_all',\n",
    "             filename_tensor_name='save/Const:0',\n",
    "             output_graph=frozen_model_file,\n",
    "             clear_devices=True,\n",
    "             initializer_nodes='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the model\n",
    "\n",
    "Check that it is producing legit captions for *One does not simply*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: vocab4.txt\n",
      "INFO:tensorflow:Created vocabulary with 38521 words\n"
     ]
    }
   ],
   "source": [
    "# Configure the model and load the vocab\n",
    "\n",
    "config = configuration.ModelConfig()\n",
    "\n",
    "vocab_file ='vocab4.txt'\n",
    "vocab = vocabulary.Vocabulary(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt\n",
      "i'm going to kill your mother but i'm not going to eat your children\n",
      "i'm going to kill your mother but i'm not going to rip your balls out\n",
      "i am superior\n",
      "i can only be a meme and one of that\n",
      "if the bible says , is a god . . . . . . . . . .\n",
      "has the best child of all sins\n",
      "has the best child of all the sacrifices he is in the world\n",
      "says he has no money left by the toilet paper\n",
      "says he has no money left by the toilet paper , in the middle class\n",
      "creates universe still doesn't exist\n",
      "creates universe still doesn't exist .\n",
      "hates gays . . . like the bible , not good enough !\n",
      "hates gays . . . like the bible , not good enough to wear it !\n",
      "i have no clue where im going to fuck you\n",
      "i have no clue where im going to rape\n",
      "says christians are racist tells christians to worship them because they are like\n",
      "says christians are racist tells christians to worship them because they are like god\n",
      "you don't give a shit about your birthday you will not give a shit\n",
      "you don't give a shit about your birthday you will not find you\n",
      "gives you a big black guy makes you come back out\n",
      "gives you a big black guy makes you come back on the internet\n",
      "i have a dream on my own property\n",
      "i have a dream when i was young i was in . . .\n",
      "you don't have a girlfriend\n",
      "you don't have a job ? that's cute .\n",
      "i have no arms i don't have no idea what i'm doing\n",
      "i have no arms i don't have no idea what i'm looking at\n",
      "the best i can see\n",
      "the best i can do is never .\n",
      "creates a religion to make you walk to heaven in the middle of the world\n",
      "creates a religion to make you walk to heaven in the middle\n",
      "i like you but i love you\n",
      "i like you but i love you too\n",
      "i may be a good god but i don't want to be afraid\n",
      "i may be a good god but i don't want to be afraid of the humans\n",
      "i'm dead .\n",
      "i'm dead , but i am the boss\n",
      "creates a bible with a shotgun doesn't kill people\n",
      "creates a bible with a shotgun doesn't want to use it\n",
      "you listen to old testament ? i'm not racist\n",
      "you listen to the other testament ? you make the perfect ones too\n",
      "has a penis , and an entire heart attack\n",
      "has a penis , and an entire heart attack . doesn't believe it .\n",
      "you want to find out ? good time .\n",
      "you want to find out ? good job ?\n",
      "gives you a gun to kill the entire other guy\n",
      "gives you a gun to kill the entire earth . gets killed by satan\n",
      "creates a meme that makes fun of the people in a country and never tells them to be\n",
      "creates a meme that makes fun of the people in a country and never tells them he is\n",
      "creates universe all for years doesn't use it\n",
      "creates universe all for years forgets to fix memes\n",
      "i have the power of this universe\n",
      "i have the power of this place\n",
      "i used to be diabetic but then i took an arrow to the knee\n",
      "i used to be diabetic then i took an arrow to the knee\n",
      "creates money to buy a new job\n",
      "creates money to buy a new car only takes 2\n",
      "thou shalt not kill people and i kill you\n",
      "thou shalt not kill people and kill the planet\n",
      "gives a blowjob to save the world the world ? all the time this is me ?\n",
      "gives a blowjob to save the world the world ? all the time this is me ? !\n",
      "gives a friend to a little friend in the middle class because of the lack of faith ,\n",
      "gives a friend to a little friend in the middle class because of the lack of faith ,\n",
      "claims religious people are the strongest atheist in the middle east can't even pronounce a word without any\n",
      "claims religious people are the strongest atheist in the middle east can't even pronounce a word without any\n",
      "gives a son a flying . and he has a headache .\n",
      "creates gays in class tries to look straight into the head\n",
      "creates gays in class tries to look straight into the head of his penis\n",
      "tells you to not leave the room\n",
      "tells you to not leave the house when you give a fuck\n",
      "makes a status about the internet\n",
      "makes a status about the internet must be done with it\n",
      "makes a meme about harry potter\n",
      "makes a meme about what is wrong with the word\n",
      "create the earth and the universe dies\n",
      "create the earth and the universe dies before\n",
      "hey son , i was born with that\n",
      "hey son , i was born with you !\n",
      "i created the bible for a reason\n",
      "i created the internet for the last time that was all my life\n",
      "creates universe to make a meme creates the universe\n",
      "creates universe to make a meme creates them and downvote all of them\n",
      "god created the universe !\n",
      "you got this meme\n",
      "you used a sword as a bitch\n",
      "i'm going to make you a sandwich with you with no\n",
      "i'm going to make you a sandwich with you with no head if you know what i mean\n",
      "oh god , i can't hear you over the sound !\n",
      "oh god , i can't hear you over the sound of my brain .\n",
      "the bible is the definition of the universe .\n",
      "the bible is the definition of the universe . . . the universe ! ! !\n",
      "you don't know what i say ? that sounds like a guy\n",
      "you don't know what i say ? that sounds like a baby . . .\n",
      "this is that .\n",
      "this is that . . . . that i don't care\n",
      "create it to be a meme of all the time !\n",
      "create it to be a meme of all the time ! of which one does not matter\n"
     ]
    }
   ],
   "source": [
    "# Generate captions on a hard-coded image\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "  restore_fn(sess)\n",
    "  generator = caption_generator.CaptionGenerator(\n",
    "      model, vocab, beam_size=beam_size)\n",
    "  for i,filename in enumerate(['memes/advice-god.jpg']):\n",
    "    with tf.gfile.GFile(filename, \"rb\") as f:\n",
    "      image = Image.open(f)\n",
    "      image = ((np.array(image.resize((299,299)))/255.0)-0.5)*2.0\n",
    "    for k in range(50):\n",
    "      captions = generator.beam_search(sess, image)    \n",
    "      for i, caption in enumerate(captions):\n",
    "        sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "        sentence = \" \".join(sentence)\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model to CoreML\n",
    "\n",
    "Specify output variables from the graph to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic shapes\n",
    "# If using Memeception, add 'image_feed:0': [299, 299, 3]\n",
    "input_tensor_shapes = {\n",
    "    'seq_embeddings:0': [1, beam_size, 300],\n",
    "    'lstm/state_feed:0': [1, beam_size, 1024],\n",
    "}\n",
    "\n",
    "coreml_model_file = './Textgen_NEW.mlmodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor_names = [node + ':0' for node in output_node_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 90 tensors. Executing graph to determine shapes. \n",
      "Automatic shape interpretation succeeded for input blob lstm/state_feed:0\n",
      "1/146: Analysing op name: seq_embeddings ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "2/146: Analysing op name: lstm/basic_lstm_cell/kernel ( type:  Const )\n",
      "3/146: Analysing op name: lstm/basic_lstm_cell/kernel/read ( type:  Identity )\n",
      "4/146: Analysing op name: lstm/basic_lstm_cell/bias ( type:  Const )\n",
      "5/146: Analysing op name: lstm/basic_lstm_cell/bias/read ( type:  Identity )\n",
      "6/146: Analysing op name: lstm/state_feed ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "7/146: Analysing op name: lstm/ExpandDims/dim ( type:  Const )\n",
      "8/146: Analysing op name: lstm/ExpandDims ( type:  ExpandDims )\n",
      "9/146: Analysing op name: lstm/split/split_dim ( type:  Const )\n",
      "10/146: Analysing op name: lstm/split ( type:  Split )\n",
      "11/146: Analysing op name: lstm/Squeeze ( type:  Squeeze )\n",
      "12/146: Analysing op name: lstm/Squeeze_1 ( type:  Squeeze )\n",
      "13/146: Analysing op name: lstm/basic_lstm_cell/concat_1/axis ( type:  Const )\n",
      "14/146: Analysing op name: lstm/basic_lstm_cell/concat_1 ( type:  ConcatV2 )\n",
      "15/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_8 ( type:  Squeeze )\n",
      "16/146: Analysing op name: lstm/basic_lstm_cell/transpose/Rank ( type:  Rank )\n",
      "17/146: Analysing op name: lstm/basic_lstm_cell/transpose/sub/y ( type:  Const )\n",
      "18/146: Analysing op name: lstm/basic_lstm_cell/transpose/sub ( type:  Sub )\n",
      "19/146: Analysing op name: lstm/basic_lstm_cell/transpose/Range/start ( type:  Const )\n",
      "20/146: Analysing op name: lstm/basic_lstm_cell/transpose/Range/delta ( type:  Const )\n",
      "21/146: Analysing op name: lstm/basic_lstm_cell/transpose/Range ( type:  Range )\n",
      "22/146: Analysing op name: lstm/basic_lstm_cell/transpose/sub_1 ( type:  Sub )\n",
      "23/146: Analysing op name: lstm/basic_lstm_cell/transpose ( type:  Transpose )\n",
      "24/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_2/dim ( type:  Const )\n",
      "25/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_2 ( type:  ExpandDims )\n",
      "26/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_3/dim ( type:  Const )\n",
      "27/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_3 ( type:  ExpandDims )\n",
      "28/146: Analysing op name: lstm/basic_lstm_cell/split_1/split_dim ( type:  Const )\n",
      "29/146: Analysing op name: lstm/basic_lstm_cell/split_1 ( type:  Split )\n",
      "30/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_9 ( type:  Squeeze )\n",
      "31/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_10 ( type:  Squeeze )\n",
      "32/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/Rank ( type:  Rank )\n",
      "33/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_11 ( type:  Squeeze )\n",
      "34/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_12 ( type:  Squeeze )\n",
      "35/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/Rank ( type:  Rank )\n",
      "36/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/sub/y ( type:  Const )\n",
      "37/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/sub ( type:  Sub )\n",
      "38/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/Range/start ( type:  Const )\n",
      "39/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/Range/delta ( type:  Const )\n",
      "40/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/Range ( type:  Range )\n",
      "41/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/sub_1 ( type:  Sub )\n",
      "42/146: Analysing op name: lstm/basic_lstm_cell/transpose_1 ( type:  Transpose )\n",
      "43/146: Analysing op name: lstm/basic_lstm_cell/MatMul_1 ( type:  MatMul )\n",
      "44/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/sub/y ( type:  Const )\n",
      "45/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/sub ( type:  Sub )\n",
      "46/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/Range/start ( type:  Const )\n",
      "47/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/Range/delta ( type:  Const )\n",
      "48/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/Range ( type:  Range )\n",
      "49/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/sub_1 ( type:  Sub )\n",
      "50/146: Analysing op name: lstm/basic_lstm_cell/transpose_2 ( type:  Transpose )\n",
      "51/146: Analysing op name: lstm/basic_lstm_cell/MatMul_2 ( type:  MatMul )\n",
      "52/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_4/dim ( type:  Const )\n",
      "53/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_4 ( type:  ExpandDims )\n",
      "54/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_5/dim ( type:  Const )\n",
      "55/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_5 ( type:  ExpandDims )\n",
      "56/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_6/dim ( type:  Const )\n",
      "57/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_6 ( type:  ExpandDims )\n",
      "58/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_7/dim ( type:  Const )\n",
      "59/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_7 ( type:  ExpandDims )\n",
      "60/146: Analysing op name: lstm/basic_lstm_cell/concat_2/axis ( type:  Const )\n",
      "61/146: Analysing op name: lstm/basic_lstm_cell/concat_2 ( type:  ConcatV2 )\n",
      "62/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_13 ( type:  Squeeze )\n",
      "63/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_14 ( type:  Squeeze )\n",
      "64/146: Analysing op name: lstm/basic_lstm_cell/BiasAdd_1 ( type:  BiasAdd )\n",
      "65/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_8/dim ( type:  Const )\n",
      "66/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_8 ( type:  ExpandDims )\n",
      "67/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_9/dim ( type:  Const )\n",
      "68/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_9 ( type:  ExpandDims )\n",
      "69/146: Analysing op name: lstm/basic_lstm_cell/split_2/split_dim ( type:  Const )\n",
      "70/146: Analysing op name: lstm/basic_lstm_cell/split_2 ( type:  Split )\n",
      "71/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_15 ( type:  Squeeze )\n",
      "72/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_16 ( type:  Squeeze )\n",
      "73/146: Analysing op name: lstm/basic_lstm_cell/Sigmoid_4 ( type:  Sigmoid )\n",
      "74/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_17 ( type:  Squeeze )\n",
      "75/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_18 ( type:  Squeeze )\n",
      "76/146: Analysing op name: lstm/basic_lstm_cell/Tanh_2 ( type:  Tanh )\n",
      "77/146: Analysing op name: lstm/basic_lstm_cell/Mul_4 ( type:  Mul )\n",
      "78/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_19 ( type:  Squeeze )\n",
      "79/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_20 ( type:  Squeeze )\n",
      "80/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_21 ( type:  Squeeze )\n",
      "81/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_22 ( type:  Squeeze )\n",
      "82/146: Analysing op name: lstm/basic_lstm_cell/Sigmoid_5 ( type:  Sigmoid )\n",
      "83/146: Analysing op name: lstm/basic_lstm_cell/Const_4 ( type:  Const )\n",
      "84/146: Analysing op name: lstm/basic_lstm_cell/Add_2 ( type:  Add )\n",
      "85/146: Analysing op name: lstm/basic_lstm_cell/Sigmoid_3 ( type:  Sigmoid )\n",
      "86/146: Analysing op name: lstm/basic_lstm_cell/Mul_3 ( type:  Mul )\n",
      "87/146: Analysing op name: lstm/basic_lstm_cell/Add_3 ( type:  Add )\n",
      "88/146: Analysing op name: lstm/basic_lstm_cell/Tanh_3 ( type:  Tanh )\n",
      "89/146: Analysing op name: lstm/basic_lstm_cell/Mul_5 ( type:  Mul )\n",
      "90/146: Analysing op name: logits/Squeeze ( type:  Squeeze )\n",
      "91/146: Analysing op name: logits/transpose/Rank ( type:  Rank )\n",
      "92/146: Analysing op name: lstm/state/axis ( type:  Const )\n",
      "93/146: Analysing op name: lstm/state ( type:  ConcatV2 )\n",
      "94/146: Analysing op name: logits/weights ( type:  Const )\n",
      "95/146: Analysing op name: logits/weights/read ( type:  Identity )\n",
      "96/146: Analysing op name: logits/biases ( type:  Const )\n",
      "97/146: Analysing op name: logits/biases/read ( type:  Identity )\n",
      "98/146: Analysing op name: logits/transpose/sub/y ( type:  Const )\n",
      "99/146: Analysing op name: logits/transpose/sub ( type:  Sub )\n",
      "100/146: Analysing op name: logits/transpose/Range/start ( type:  Const )\n",
      "101/146: Analysing op name: logits/transpose/Range/delta ( type:  Const )\n",
      "102/146: Analysing op name: logits/transpose/Range ( type:  Range )\n",
      "103/146: Analysing op name: logits/transpose/sub_1 ( type:  Sub )\n",
      "104/146: Analysing op name: logits/transpose ( type:  Transpose )\n",
      "105/146: Analysing op name: logits/ExpandDims/dim ( type:  Const )\n",
      "106/146: Analysing op name: logits/ExpandDims ( type:  ExpandDims )\n",
      "107/146: Analysing op name: logits/ExpandDims_1/dim ( type:  Const )\n",
      "108/146: Analysing op name: logits/ExpandDims_1 ( type:  ExpandDims )\n",
      "109/146: Analysing op name: logits/split/split_dim ( type:  Const )\n",
      "110/146: Analysing op name: logits/split ( type:  Split )\n",
      "111/146: Analysing op name: logits/Squeeze_1 ( type:  Squeeze )\n",
      "112/146: Analysing op name: logits/Squeeze_2 ( type:  Squeeze )\n",
      "113/146: Analysing op name: logits/transpose_1/Rank ( type:  Rank )\n",
      "114/146: Analysing op name: logits/Squeeze_3 ( type:  Squeeze )\n",
      "115/146: Analysing op name: logits/Squeeze_4 ( type:  Squeeze )\n",
      "116/146: Analysing op name: logits/transpose_2/Rank ( type:  Rank )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/146: Analysing op name: logits/transpose_1/sub/y ( type:  Const )\n",
      "118/146: Analysing op name: logits/transpose_1/sub ( type:  Sub )\n",
      "119/146: Analysing op name: logits/transpose_1/Range/start ( type:  Const )\n",
      "120/146: Analysing op name: logits/transpose_1/Range/delta ( type:  Const )\n",
      "121/146: Analysing op name: logits/transpose_1/Range ( type:  Range )\n",
      "122/146: Analysing op name: logits/transpose_1/sub_1 ( type:  Sub )\n",
      "123/146: Analysing op name: logits/transpose_1 ( type:  Transpose )\n",
      "124/146: Analysing op name: logits/MatMul ( type:  MatMul )\n",
      "125/146: Analysing op name: logits/transpose_2/sub/y ( type:  Const )\n",
      "126/146: Analysing op name: logits/transpose_2/sub ( type:  Sub )\n",
      "127/146: Analysing op name: logits/transpose_2/Range/start ( type:  Const )\n",
      "128/146: Analysing op name: logits/transpose_2/Range/delta ( type:  Const )\n",
      "129/146: Analysing op name: logits/transpose_2/Range ( type:  Range )\n",
      "130/146: Analysing op name: logits/transpose_2/sub_1 ( type:  Sub )\n",
      "131/146: Analysing op name: logits/transpose_2 ( type:  Transpose )\n",
      "132/146: Analysing op name: logits/MatMul_1 ( type:  MatMul )\n",
      "133/146: Analysing op name: logits/ExpandDims_2/dim ( type:  Const )\n",
      "134/146: Analysing op name: logits/ExpandDims_2 ( type:  ExpandDims )\n",
      "135/146: Analysing op name: logits/ExpandDims_3/dim ( type:  Const )\n",
      "136/146: Analysing op name: logits/ExpandDims_3 ( type:  ExpandDims )\n",
      "137/146: Analysing op name: logits/ExpandDims_4/dim ( type:  Const )\n",
      "138/146: Analysing op name: logits/ExpandDims_4 ( type:  ExpandDims )\n",
      "139/146: Analysing op name: logits/ExpandDims_5/dim ( type:  Const )\n",
      "140/146: Analysing op name: logits/ExpandDims_5 ( type:  ExpandDims )\n",
      "141/146: Analysing op name: logits/concat/axis ( type:  Const )\n",
      "142/146: Analysing op name: logits/concat ( type:  ConcatV2 )\n",
      "143/146: Analysing op name: logits/Squeeze_5 ( type:  Squeeze )\n",
      "144/146: Analysing op name: logits/Squeeze_6 ( type:  Squeeze )\n",
      "145/146: Analysing op name: logits/BiasAdd ( type:  BiasAdd )\n",
      "146/146: Analysing op name: softmax ( type:  Softmax )\n",
      "\n",
      " Core ML model generated. Saved at location: ./Textgen_NEW.mlmodel \n",
      "\n",
      "Core ML input(s): \n",
      " [name: \"seq_embeddings__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 300\n",
      "    shape: 1\n",
      "    shape: 2\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      ", name: \"lstm__state_feed__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 1024\n",
      "    shape: 1\n",
      "    shape: 2\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "Core ML output(s): \n",
      " [name: \"lstm__state__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      ", name: \"softmax__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file, \n",
    "        mlmodel_path=coreml_model_file, \n",
    "        input_name_shape_dict=input_tensor_shapes,\n",
    "        output_feature_names=output_tensor_names,\n",
    "        add_custom_layers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "Run a predictable randomly seeded inputs through and see where the disparities are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_rand = np.random.rand(300)\n",
    "seq_embeddings_tf = np.array([[seq_rand, seq_rand]])\n",
    "seq_embeddings_ml = np.array([[[sr, sr]] for sr in seq_rand])\n",
    "\n",
    "state_rand = np.random.rand(1024)\n",
    "state_feed_tf = np.array([[state_rand, state_rand]])\n",
    "state_feed_ml = np.array([[[sr, sr]] for sr in state_rand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm__state__0\n",
      "(1, 1, 1024, 1, 2)\n",
      "[[[[[ 0.02476783  0.02476783]]\n",
      "\n",
      "   [[ 0.48451838  0.48451838]]\n",
      "\n",
      "   [[-0.62699652 -0.62699652]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 0.07591341  0.07591341]]\n",
      "\n",
      "   [[ 0.0847      0.0847    ]]\n",
      "\n",
      "   [[ 0.53388256  0.53388256]]]]]\n",
      "softmax__0\n",
      "(1, 1, 38521, 1, 2)\n",
      "[[[[[6.80646144e-06 6.80646144e-06]]\n",
      "\n",
      "   [[2.66360911e-03 2.66360911e-03]]\n",
      "\n",
      "   [[6.77036634e-03 6.77036634e-03]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[1.83542836e-02 1.83542836e-02]]\n",
      "\n",
      "   [[4.50125071e-06 4.50125071e-06]]\n",
      "\n",
      "   [[7.38304108e-02 7.38304108e-02]]]]]\n"
     ]
    }
   ],
   "source": [
    "coreml_inputs = {\n",
    "    'seq_embeddings__0': seq_embeddings_ml,\n",
    "    'lstm__state_feed__0': state_feed_ml,\n",
    "}\n",
    "coreml_output = coreml_model.predict(coreml_inputs, useCPUOnly=True)\n",
    "# print(coreml_output['lstm__state__0'].shape)\n",
    "# print(coreml_output['softmax__0'].shape)\n",
    "# print(coreml_output['softmax__0'].reshape(38521, 1, 2))\n",
    "# print(coreml_output)\n",
    "def print_ml(ml):\n",
    "    for key in sorted(ml.keys()):\n",
    "        print(key)\n",
    "        print(ml[key].shape)\n",
    "        print(ml[key])\n",
    "print_ml(coreml_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt\n",
      "lstm/state:0\n",
      "(1, 2, 1024)\n",
      "[[[ 0.02476783  0.48451832 -0.62699634 ...  0.07591344  0.08469999\n",
      "    0.53388274]\n",
      "  [ 0.02476783  0.48451832 -0.62699634 ...  0.07591344  0.08469999\n",
      "    0.53388274]]]\n",
      "softmax:0\n",
      "(2, 38521)\n",
      "[[6.8064519e-06 2.6636065e-03 6.7703538e-03 ... 1.8354276e-02\n",
      "  4.5012448e-06 7.3830307e-02]\n",
      " [6.8064519e-06 2.6636065e-03 6.7703538e-03 ... 1.8354276e-02\n",
      "  4.5012448e-06 7.3830307e-02]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    # Load the model from checkpoint.\n",
    "    restore_fn(sess)\n",
    "    input_names = ['lstm/state:0', 'softmax:0']\n",
    "    output_values = sess.run(\n",
    "        fetches=input_names,\n",
    "        feed_dict={\n",
    "            #\"input_feed:0\": input_feed,\n",
    "            \"lstm/state_feed:0\": state_feed_tf,\n",
    "            \"seq_embeddings:0\": seq_embeddings_tf,\n",
    "            #\"seq_embedding/embedding_map:0\": self.embedding_map\n",
    "        })\n",
    "    for (index, value) in sorted(enumerate(input_names), key=lambda x: x[1]):\n",
    "        print(value)\n",
    "        print(output_values[index].shape)\n",
    "        print(output_values[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 45)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(np.random.rand(1, 20), np.random.rand(20, 45)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 812)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1, 2, 812)[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
