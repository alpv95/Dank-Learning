{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ALP/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#some basic imports and setups\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#mean of imagenet dataset in BGR\n",
    "imagenet_mean = np.array([104., 117., 124.], dtype=np.float32)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "image_dir = os.path.join(current_dir, 'memes')\n",
    "#image_dir = current_dir\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get list of all images\n",
    "img_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('ting.jpg')]\n",
    "print(len(img_files))\n",
    "#load all images\n",
    "imgs = []\n",
    "for f in img_files:\n",
    "    img = Image.open(f)\n",
    "    img.thumbnail((227, 227), Image.ANTIALIAS)\n",
    "    #img = img.resize((227,227))\n",
    "    assert np.shape(img) == (227, 227, 3)\n",
    "    imgs.append(img)\n",
    "#use img.thumbnail for square images, img.resize for non square\n",
    "    \n",
    "#plot images\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "for i, img in enumerate(imgs):\n",
    "    fig.add_subplot(1,len(imgs),i+1)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from alexnet import AlexNet\n",
    "from caffe_classes import class_names\n",
    "\n",
    "#placeholder for input and dropout rate\n",
    "x = tf.placeholder(tf.float32, [1, 227, 227, 3])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#create model with default config ( == no skip_layer and 1000 units in the last layer)\n",
    "model = AlexNet(x, keep_prob, 1000,[],['fc7','fc8'],512) #maybe need to put fc8 in skip_layers\n",
    "\n",
    "#define activation of last layer as score\n",
    "score = model.fc6\n",
    "\n",
    "#create op to calculate softmax \n",
    "#softmax = tf.nn.softmax(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Load the pretrained weights into the model\n",
    "    model.load_initial_weights(sess)\n",
    "    \n",
    "# Create figure handle\n",
    "    fig2 = plt.figure(figsize=(15,6))\n",
    "    \n",
    "    # Loop over all images\n",
    "    for i, image in enumerate(imgs):\n",
    "        \n",
    "        # Convert image to float32 and resize to (227x227)\n",
    "        #img = cv2.resize(image.astype(np.float32), (227,227))\n",
    "        \n",
    "        # Subtract the ImageNet mean\n",
    "        img = image - imagenet_mean\n",
    "        \n",
    "        # Reshape as needed to feed into model\n",
    "        img = img.reshape((1,227,227,3))\n",
    "        \n",
    "        # Run the session and calculate the class probability\n",
    "        #probs = sess.run(softmax, feed_dict={x: img, keep_prob: 1})\n",
    "        probs = sess.run(score, feed_dict={x: img, keep_prob: 1})\n",
    "        \n",
    "        # Get the class name of the class with the highest probability\n",
    "        #class_name = class_names[np.argmax(probs)]\n",
    "        \n",
    "        \n",
    "        # Plot image with class name and prob in the title\n",
    "        fig2.add_subplot(len(imgs),1,i+1)\n",
    "        plt.imshow(image)\n",
    "        #plt.title(\"Class: \" + class_name + \", probability: %.4f\" %probs[0,np.argmax(probs)])\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Vector: \" + \"%.4f\" %probs[0,0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs[0,:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.argsort(probs)\n",
    "for i in range(990,1000):\n",
    "    print(class_names[int(ind[0][i])])\n",
    "    print(probs[0,ind[0][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(probs[0,:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Converting captions and meme vector representations into single Tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires putting memes through alexnet to find their vector rep, shuffling the captions, changing captions into their word2idx, finally saving one caption together with one meme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('captions.txt','r') as f:\n",
    "    captions = f.readlines()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "captions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "captions = list(set(captions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "captions = [s.lower() for s in captions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('jpg')]\n",
    "print(len(img_files))\n",
    "img_files = list(set(img_files))\n",
    "print(len(img_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meme_name = img_files[2500].replace('/Users/ALP/Desktop/Stanford/CS224n/MemeProject/memes/','')\n",
    "meme_name = meme_name.replace('.jpg','')\n",
    "meme_name = meme_name.replace('-',' ').lower()\n",
    "meme_name = 'dolan'\n",
    "print(meme_name)\n",
    "match = [s for s in captions if meme_name in s]\n",
    "#print(match)\n",
    "#match[0].replace(meme_name + ' - ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 47, 47)\n",
      "(100, 16392, 16392)\n",
      "(200, 31906, 31906)\n",
      "(300, 48510, 48510)\n",
      "sizing error\n",
      "(400, 63233, 63233)\n",
      "sizing error\n",
      "sizing error\n",
      "(500, 82378, 82378)\n",
      "(600, 99104, 99104)\n",
      "sizing error\n",
      "(700, 117784, 117784)\n",
      "sizing error\n",
      "sizing error\n",
      "sizing error\n",
      "(800, 135181, 135181)\n",
      "sizing error\n",
      "sizing error\n",
      "sizing error\n",
      "(900, 157895, 157895)\n",
      "sizing error\n",
      "(1000, 173665, 173665)\n",
      "(1100, 188584, 188584)\n",
      "(1200, 204294, 204294)\n",
      "sizing error\n",
      "(1300, 260643, 260643)\n",
      "sizing error\n",
      "(1400, 288299, 288299)\n",
      "sizing error\n",
      "sizing error\n",
      "(1500, 308865, 308865)\n",
      "sizing error\n",
      "sizing error\n",
      "sizing error\n",
      "sizing error\n",
      "(1600, 325910, 325910)\n",
      "sizing error\n",
      "sizing error\n",
      "sizing error\n",
      "(1700, 342184, 342184)\n",
      "sizing error\n",
      "sizing error\n",
      "sizing error\n",
      "(1800, 361982, 361982)\n",
      "sizing error\n",
      "sizing error\n",
      "(1900, 377921, 377921)\n",
      "sizing error\n",
      "(2000, 394047, 394047)\n",
      "(2100, 414961, 414961)\n",
      "(2200, 432000, 432000)\n",
      "sizing error\n",
      "(2300, 447984, 447984)\n",
      "sizing error\n",
      "(2400, 463529, 463529)\n",
      "sizing error\n",
      "sizing error\n",
      "(2500, 481561, 481561)\n"
     ]
    }
   ],
   "source": [
    "img_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('jpg')]\n",
    "with open('captions.txt','r') as f:\n",
    "    captions = f.readlines()\n",
    "captions = list(set(captions))\n",
    "captions = [s.lower() for s in captions]\n",
    "data_memes = []\n",
    "data_captions = []\n",
    "\n",
    "#Doing everything in one script: (the fc6 vectors are quite sparse)\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Load the pretrained weights into the model\n",
    "    model.load_initial_weights(sess)\n",
    "    \n",
    "    for i,meme in enumerate(img_files):\n",
    "        meme_name = meme.replace('/Users/ALP/Desktop/Stanford/CS224n/MemeProject/memes/','')\n",
    "        meme_name = meme_name.replace('.jpg','').lower()\n",
    "        meme_name = meme_name.replace('-',' ')\n",
    "        img = Image.open(meme)\n",
    "        try:\n",
    "            img.thumbnail((227, 227), Image.ANTIALIAS)\n",
    "            #img = img.resize((227,227))\n",
    "            #use img.thumbnail for square images, img.resize for non square\n",
    "            assert np.shape(img) == (227, 227, 3)\n",
    "        except AssertionError:\n",
    "            img = img.resize((227,227))\n",
    "            print('sizing error')\n",
    "        \n",
    "        # Subtract the ImageNet mean\n",
    "        img = img - imagenet_mean #should probably change this\n",
    "        \n",
    "        # Reshape as needed to feed into model\n",
    "        img = img.reshape((1,227,227,3))\n",
    "\n",
    "        meme_vector = sess.run(score, feed_dict={x: img, keep_prob: 1}) #[1,4096]\n",
    "        meme_vector = np.reshape(meme_vector,[4096])\n",
    "        assert np.shape(meme_vector) == (4096,)\n",
    "        match = [s.split('-',1)[-1].lstrip() for s in captions if meme_name in s]\n",
    "        \n",
    "        #now save in tfrecords format, or prepare for that action\n",
    "        meme_vectors = [meme_vector for cap in match]\n",
    "        assert len(meme_vectors) == len(match)\n",
    "        data_memes.extend(meme_vectors)\n",
    "        data_captions.extend(match)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(i,len(data_memes),len(data_captions))\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gooby pls\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_captions[180000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482207"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363585"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(data_captions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deleters = []\n",
    "for i,ting in enumerate(data_captions):\n",
    "    if ting == '':\n",
    "        deleters.append(i)\n",
    "for i,ting in enumerate(deleters):\n",
    "    del data_captions[ting-i]\n",
    "    del data_memes[ting-i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "word_captions = []\n",
    "for capt in data_captions:\n",
    "    words = re.findall(r\"[\\w']+|[.,!?;'><(){}%$#£@-_+=|\\/~`^&*]\", capt)\n",
    "    word_captions.append(words)\n",
    "#print(len(word_captions))\n",
    "#word_captions = list(set(word_captions))\n",
    "#print(len(word_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocabulary.\n",
      "('Total words:', 144789)\n",
      "('Words in vocabulary:', 50007)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"Creating vocabulary.\")\n",
    "counter = Counter()\n",
    "for c in word_captions:\n",
    "    counter.update(c)\n",
    "print(\"Total words:\", len(counter))\n",
    "\n",
    "# Filter uncommon words and sort by descending count.\n",
    "word_counts = [x for x in counter.items() if x[1] >= 3]\n",
    "word_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"Words in vocabulary:\", len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vocabulary dictionary.\n",
    "reverse_vocab = [x[0] for x in word_counts]\n",
    "#unk_id = len(reverse_vocab)\n",
    "vocab_dict = dict([(x, y) for (y, x) in enumerate(reverse_vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"laden's\""
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_vocab[30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "180000\n",
      "200000\n",
      "220000\n",
      "240000\n",
      "260000\n",
      "280000\n",
      "300000\n",
      "320000\n",
      "340000\n",
      "360000\n",
      "380000\n",
      "400000\n",
      "420000\n",
      "440000\n",
      "460000\n",
      "480000\n",
      "500000\n",
      "520000\n",
      "540000\n",
      "560000\n",
      "580000\n",
      "600000\n",
      "620000\n",
      "640000\n",
      "660000\n",
      "680000\n",
      "700000\n",
      "720000\n",
      "740000\n",
      "760000\n",
      "780000\n",
      "800000\n",
      "820000\n",
      "840000\n",
      "860000\n",
      "880000\n",
      "900000\n",
      "920000\n",
      "940000\n",
      "960000\n",
      "980000\n",
      "1000000\n",
      "1020000\n",
      "1040000\n",
      "1060000\n",
      "1080000\n",
      "1100000\n",
      "1120000\n",
      "1140000\n",
      "1160000\n",
      "1180000\n",
      "1200000\n",
      "1220000\n",
      "1240000\n",
      "1260000\n",
      "1280000\n",
      "1300000\n",
      "1320000\n",
      "1340000\n",
      "1360000\n",
      "1380000\n",
      "1400000\n",
      "1420000\n",
      "1440000\n",
      "1460000\n",
      "1480000\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIMENSION=300 # Available dimensions for 6B data is 50, 100, 200, 300\n",
    "data_directory = '~/Desktop/Stanford/CS224n/MemeProject'\n",
    "\n",
    "PAD_TOKEN = 0\n",
    "\n",
    "word2idx = { 'PAD': PAD_TOKEN } # dict so we can lookup indices for tokenising our text later from string to sequence of integers\n",
    "weights = []\n",
    "index_counter = 0\n",
    "\n",
    "with open('glove.42B.300d.txt','r') as file:\n",
    "    for index, line in enumerate(file):\n",
    "        values = line.split() # Word and weights separated by space\n",
    "        word = values[0] # Word is first symbol on each line\n",
    "        if word in vocab_dict:\n",
    "            index_counter += 1\n",
    "            word_weights = np.asarray(values[1:], dtype=np.float32) # Remainder of line is weights for word\n",
    "            word2idx[word] = index_counter # PAD is our zeroth index so shift by one\n",
    "            weights.append(word_weights)\n",
    "        if index % 20000 == 0:\n",
    "            print(index)\n",
    "        if index + 1 == 1500000:\n",
    "            # Limit vocabulary to top 40k terms\n",
    "            break\n",
    "\n",
    "EMBEDDING_DIMENSION = len(weights[0])\n",
    "# Insert the PAD weights at index 0 now we know the embedding dimension\n",
    "weights.insert(0, np.random.randn(EMBEDDING_DIMENSION))\n",
    "\n",
    "# Append unknown and pad to end of vocab and initialize as random #maybe include start and end token here\n",
    "UNKNOWN_TOKEN=len(weights)\n",
    "word2idx['UNK'] = UNKNOWN_TOKEN\n",
    "word2idx['<S>'] = UNKNOWN_TOKEN + 1\n",
    "word2idx['</S>'] = UNKNOWN_TOKEN + 2\n",
    "weights.append(np.random.randn(EMBEDDING_DIMENSION))\n",
    "weights.append(np.random.randn(EMBEDDING_DIMENSION))\n",
    "weights.append(np.random.randn(EMBEDDING_DIMENSION))\n",
    "\n",
    "# Construct our final vocab\n",
    "weights = np.asarray(weights, dtype=np.float32)\n",
    "\n",
    "VOCAB_SIZE=weights.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44441"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.0359e-02,  3.7314e-01,  8.4125e-01, -4.2265e-01,  4.5491e-01,\n",
       "        5.6615e-04,  3.5665e-01, -1.4396e-01, -1.9230e-01, -7.9809e-02,\n",
       "       -1.2958e-01, -3.8674e-01, -5.6218e-01,  1.5008e-01, -4.2598e-03,\n",
       "        9.3853e-02, -7.2554e-02, -1.3782e-01,  2.3828e-01, -3.0293e-01,\n",
       "        6.1546e-01, -3.1938e-01, -4.1319e-01,  5.6263e-01, -1.8095e-02,\n",
       "        2.5644e-01, -5.2713e-01, -5.4342e-01,  4.7497e-01, -4.8145e-01,\n",
       "        2.9435e-01, -3.7791e-01, -3.4553e-01,  5.3498e-01,  4.0645e-02,\n",
       "        3.2537e-01,  2.9631e-01,  6.4424e-02, -7.0116e-01,  2.9082e-01,\n",
       "        1.6313e-01,  1.6526e-01,  5.1509e-01, -4.9002e-02,  5.0856e-01,\n",
       "       -3.5607e-01,  3.4043e-01, -1.5131e-01, -5.1105e-01, -1.9106e-01,\n",
       "       -1.6357e-01,  1.0753e-01, -3.4272e-01, -4.6286e-01,  3.8970e-01,\n",
       "        7.1378e-02, -1.3887e-01,  6.8614e-03,  7.3723e-01,  4.8359e-01,\n",
       "       -4.3565e-01, -2.3027e-02,  2.0262e-01, -2.3029e-01,  7.4993e-01,\n",
       "       -4.4941e-02,  4.0742e-01, -6.0467e-03,  2.0942e-01, -1.9428e-01,\n",
       "       -1.1300e-01, -2.6174e-01, -3.7484e-02,  4.1114e-01,  7.2993e-02,\n",
       "       -4.0522e-01, -9.4495e-03, -6.1305e-02,  8.8338e-02, -4.1083e-01,\n",
       "       -1.7306e-01, -1.0956e-01, -2.3576e-01,  1.2547e-01,  4.2222e-03,\n",
       "       -2.4470e-01,  3.3267e-02,  3.9065e-01, -1.0184e-01,  6.1333e-03,\n",
       "        5.0096e-01, -1.5886e-01, -1.3280e-01,  4.5398e-01,  2.3648e-01,\n",
       "        4.4575e-01,  5.3890e-01, -1.8766e-01,  1.9019e-02,  2.3819e-02,\n",
       "       -4.5430e-01, -1.7272e-01, -6.0274e-01, -1.3826e-01,  1.9093e-01,\n",
       "       -6.4350e-01,  2.5095e-01,  4.2011e-02, -2.8795e-01,  3.7823e-02,\n",
       "       -2.5563e-01,  6.9191e-01, -2.7481e-01, -3.6442e-01, -6.7511e-01,\n",
       "       -1.0540e-01, -5.8289e-01,  3.6292e-01,  3.0307e-01, -2.0245e-01,\n",
       "       -4.8793e-02, -1.9403e-02,  1.0595e-01,  7.2726e-02, -7.5967e-01,\n",
       "       -3.7895e-01,  2.2603e-02,  1.0242e-01, -2.3964e-01, -4.4983e-01,\n",
       "        1.1112e-01, -7.7414e-02,  4.8355e-02, -1.4162e-01, -3.2657e-01,\n",
       "        2.1270e-01,  6.8277e-03, -1.9451e-01,  7.7044e-01, -4.5413e-01,\n",
       "        3.7058e-01,  1.0258e-01,  4.6971e-01, -1.7427e-01, -2.8704e-01,\n",
       "        4.0358e-01,  3.6187e-01,  3.0723e-01,  1.8215e-01, -2.1254e-01,\n",
       "        4.4425e-01,  3.0009e-01,  4.2208e-02,  3.7156e-01,  4.4184e-01,\n",
       "       -7.4939e-02, -4.8233e-01,  8.4572e-01,  3.7520e-01, -3.4865e-01,\n",
       "        1.3184e-01,  5.8858e-02,  3.6940e-01,  2.1820e-01, -6.9555e-02,\n",
       "        5.6096e-01,  3.9348e-01,  5.0154e-01,  1.6007e-02,  3.7916e-03,\n",
       "       -8.6419e-01,  5.5839e-01,  2.8982e-01, -3.8323e-02, -2.3249e-02,\n",
       "        1.8322e-01,  5.6153e-02, -5.7340e-01,  5.0210e-01,  4.4161e-01,\n",
       "        4.5465e-01, -1.4196e-01,  2.0997e-02,  2.0763e-01, -2.2164e-01,\n",
       "        1.9979e-01, -2.5514e-01, -7.8837e-03,  2.6848e-01,  9.4074e-02,\n",
       "       -2.1977e-02,  2.4289e-01, -5.6857e-01, -6.1113e-01,  2.7097e-01,\n",
       "       -1.0549e-03,  7.7273e-02, -1.4822e-01,  7.7936e-02,  6.0267e-02,\n",
       "       -1.3446e-01,  6.2997e-01,  5.9502e-01, -2.7907e-01,  8.6764e-02,\n",
       "       -9.0902e-01, -6.5371e-01,  2.6653e-01,  2.8491e-01, -2.1468e-01,\n",
       "       -2.4369e-01,  1.7693e-01, -4.3558e-01,  2.2662e-01,  6.0078e-01,\n",
       "        1.5557e-01, -6.7975e-01, -1.5427e-01,  1.8957e-01,  1.5440e-01,\n",
       "       -2.8179e-01,  4.9827e-01,  7.9156e-02,  3.7618e-01,  5.8864e-01,\n",
       "        1.8389e-01,  2.3133e-01, -5.6308e-01,  2.6624e-01,  4.6749e-01,\n",
       "        3.5002e-01,  5.3705e-01,  3.2115e-02, -1.1795e-01,  3.1920e-01,\n",
       "       -4.4885e-01,  1.4294e-01,  5.0162e-02, -3.4275e-02,  2.1373e-01,\n",
       "       -2.1506e-01,  7.7065e-01,  1.0700e-01,  4.2134e-02, -3.9453e-02,\n",
       "        8.0226e-03,  1.4425e-01, -6.8484e-01, -2.1233e-01,  3.5075e-01,\n",
       "       -5.2632e-02, -4.2329e-01,  3.9844e-01,  5.3427e-01,  5.8379e-01,\n",
       "       -1.2920e-01, -3.8835e-01, -2.6089e-02,  2.2781e-01, -5.4930e-02,\n",
       "        5.5260e-02,  1.1815e-01, -2.0100e-01, -3.7610e-01,  3.5702e-01,\n",
       "        4.2522e-01, -3.7658e-01,  2.8822e-01, -8.2650e-01,  7.8340e-01,\n",
       "        1.2518e-01,  5.2467e-01,  2.6712e-02,  7.4166e-01,  1.2152e-01,\n",
       "       -3.1628e-01,  1.5076e-01,  2.1506e-02, -2.1373e-01, -3.1130e-01,\n",
       "       -5.3052e-01, -3.7114e-02, -1.5585e-01,  2.4493e-02, -4.1399e-01,\n",
       "        4.0939e-01,  5.5948e-01,  9.0745e-02, -9.0621e-01,  5.1666e-01,\n",
       "       -1.8662e-01, -4.4574e-01, -2.2392e-01, -2.3852e-02,  7.7619e-01,\n",
       "        4.7390e-01,  1.6021e-01, -1.5210e-01,  4.7785e-02, -2.5279e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[76984]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('embedding_matrix2',weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deleters = []\n",
    "for i,ting in enumerate(data_captions):\n",
    "    if len(ting) == 2:\n",
    "        deleters.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,ting in enumerate(deleters):\n",
    "    del data_captions[ting-i]\n",
    "    del data_memes[ting-i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4346"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deleters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480918"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "token_captions = []\n",
    "for capt in data_captions:\n",
    "    token_caption = []\n",
    "    token_caption.append(word2idx['<S>'])\n",
    "    words = re.findall(r\"[\\w']+|[.,!?;'><(){}%$#£@-_+=|\\/~`^&*]\", capt)\n",
    "    for word in words:\n",
    "        try:\n",
    "            token = word2idx[word]\n",
    "        except KeyError:\n",
    "            token = word2idx['UNK']\n",
    "        token_caption.append(token)\n",
    "    token_caption.append(word2idx['</S>'])\n",
    "    token_captions.append(token_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleters = []\n",
    "for i,ting in enumerate(token_captions):\n",
    "    if len(ting) == 2:\n",
    "        deleters.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ting in enumerate(deleters):\n",
    "    del data_captions[ting-i]\n",
    "    del data_memes[ting-i]\n",
    "    del token_captions[ting-i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "c = list(zip(data_memes, token_captions))\n",
    "shuffle(c)\n",
    "memes_shuffled, captions_shuffled = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480872"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(captions_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Wrapper for inserting an int64 Feature into a SequenceExample proto.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Wrapper for inserting a bytes Feature into a SequenceExample proto.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature_list(values):\n",
    "    \"\"\"Wrapper for inserting an int64 FeatureList into a SequenceExample proto.\"\"\"\n",
    "    return tf.train.FeatureList(feature=[_int64_feature(v) for v in values])\n",
    "\n",
    "\n",
    "def _bytes_feature_list(values):\n",
    "    \"\"\"Wrapper for inserting a bytes FeatureList into a SequenceExample proto.\"\"\"\n",
    "    return tf.train.FeatureList(feature=[_bytes_feature(v) for v in values])\n",
    "\n",
    "def _floats_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15453514099           0           0           0           0           0\n",
      "           0           0           0           0           0           0\n",
      "           0 10607815742           0           0           0           0\n",
      "           0           0  7286251068           0  6433458328           0\n",
      "           0           0  5669502735           0           0           0\n",
      "           0           0  8953964233           0           0           0\n",
      "   684471011           0           0  9704100608           0           0\n",
      "           0           0           0           0           0           0\n",
      "           0           0 14654695510  4397427082           0           0\n",
      "           0           0           0           0           0           0\n",
      "           0           0  1407497406           0           0           0\n",
      "           0           0           0           0           0           0\n",
      "   136409804           0           0           0  7716796875           0\n",
      "           0           0           0           0           0           0\n",
      "           0           0           0           0           0           0\n",
      "  1233999252           0           0           0           0           0\n",
      "           0           0           0  9202254295]\n"
     ]
    }
   ],
   "source": [
    "memes_shuffled_int = []\n",
    "for i,meme in enumerate(memes_shuffled):\n",
    "    memes_shuffled_int.append(np.int_(meme*1000000000))\n",
    "print(memes_shuffled_int[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44439,\n",
       " 456,\n",
       " 999,\n",
       " 306,\n",
       " 16,\n",
       " 9,\n",
       " 7,\n",
       " 10203,\n",
       " 4,\n",
       " 184,\n",
       " 1354,\n",
       " 127,\n",
       " 1115,\n",
       " 3110,\n",
       " 13,\n",
       " 23823,\n",
       " 67,\n",
       " 44440]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(captions_shuffled[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _to_sequence_example(image, decoder, vocab):\n",
    "    \"\"\"Builds a SequenceExample proto for an image-caption pair.\n",
    "    Args:\n",
    "        image: An ImageMetadata object.\n",
    "        decoder: An ImageDecoder object.\n",
    "        vocab: A Vocabulary object.\n",
    "      Returns:\n",
    "        A SequenceExample proto.\n",
    "      \"\"\"\n",
    "    with tf.gfile.FastGFile(image.filename, \"r\") as f:\n",
    "        encoded_image = f.read()\n",
    "    \n",
    "    try:\n",
    "        decoder.decode_jpeg(encoded_image)\n",
    "    except (tf.errors.InvalidArgumentError, AssertionError):\n",
    "        print(\"Skipping file with invalid JPEG data: %s\" % image.filename)\n",
    "        return\n",
    "    \n",
    "    context = tf.train.Features(feature={\n",
    "          \"image/image_id\": _int64_feature(image.image_id),\n",
    "          \"image/data\": _bytes_feature(encoded_image),\n",
    "      })\n",
    "    \n",
    "    assert len(image.captions) == 1\n",
    "    caption = image.captions[0]\n",
    "    caption_ids = [vocab.word_to_id(word) for word in caption]\n",
    "    feature_lists = tf.train.FeatureLists(feature_list={\n",
    "          \"image/caption\": _bytes_feature_list(caption),\n",
    "          \"image/caption_ids\": _int64_feature_list(caption_ids)\n",
    "      })\n",
    "    sequence_example = tf.train.SequenceExample(\n",
    "          context=context, feature_lists=feature_lists)\n",
    "    \n",
    "    return sequence_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 0/480872\n",
      "Train data: 20000/480872\n",
      "Train data: 40000/480872\n",
      "Train data: 60000/480872\n",
      "Train data: 80000/480872\n",
      "Train data: 100000/480872\n",
      "Train data: 120000/480872\n",
      "Train data: 140000/480872\n",
      "Train data: 160000/480872\n",
      "Train data: 180000/480872\n",
      "Train data: 200000/480872\n",
      "Train data: 220000/480872\n",
      "Train data: 240000/480872\n",
      "Train data: 260000/480872\n",
      "Train data: 280000/480872\n",
      "Train data: 300000/480872\n",
      "Train data: 320000/480872\n",
      "Train data: 340000/480872\n",
      "Train data: 360000/480872\n",
      "Train data: 380000/480872\n",
      "Train data: 400000/480872\n",
      "Train data: 420000/480872\n",
      "Train data: 440000/480872\n",
      "Train data: 460000/480872\n",
      "Train data: 480000/480872\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "train_filename = 'train.tfrecords4'  # address to save the TFRecords file\n",
    "# open the TFRecords file\n",
    "writer = tf.python_io.TFRecordWriter(train_filename)\n",
    "for i in range(len(memes_shuffled_int)):\n",
    "    if not i % 20000:\n",
    "        print 'Train data: {}/{}'.format(i, len(memes_shuffled_int))\n",
    "        sys.stdout.flush()\n",
    "    context = tf.train.Features(feature={\n",
    "          \"train/meme\": _bytes_feature(memes_shuffled_int[i].tostring()),  #this is the part that needs to be a float save\n",
    "      })\n",
    "    feature_lists = tf.train.FeatureLists(feature_list={\n",
    "          \"train/captions\": _int64_feature_list(captions_shuffled[i])\n",
    "      })\n",
    "    sequence_example = tf.train.SequenceExample(\n",
    "          context=context, feature_lists=feature_lists)\n",
    "    \n",
    "    writer.write(sequence_example.SerializeToString())\n",
    "    \n",
    "writer.close()\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
