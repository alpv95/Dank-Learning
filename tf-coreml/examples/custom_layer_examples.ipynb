{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the process of adding custom layers to the CoreML model during conversion. We discuss  three examples.\n",
    "\n",
    "For TensorFlow operations (ops for short) that are not translatable to any of the CoreML layers, custom layers can be inserted in the CoreML model (list of CoreML layers can be found [here](https://github.com/apple/coremltools/blob/master/mlmodel/format/NeuralNetwork.proto) or [here](https://apple.github.io/coremltools/coremlspecification/sections/NeuralNetwork.html)). At runtime, CoreML framework will look for the implementation code of the custom layers, which has to be provided by the developer in her app.   \n",
    "Custom layer is a [proto message](https://github.com/apple/coremltools/blob/5b5b8190764ffe78110be6b4d0edbeebe0253a6e/mlmodel/format/NeuralNetwork.proto#L2280), like any other neural network layer in the .mlmodel file (which is in the protobuf format), that can hold the parameters and weights (if any) associated with the TF op.\n",
    "Here is the [documentation](https://developer.apple.com/documentation/coreml/core_ml_api/creating_a_custom_layer) on CoreML custom layers and a nice detailed [blogpost](http://machinethink.net/blog/coreml-custom-layers/). \n",
    "\n",
    "There are two ways in which a custom layer can be added during conversion from TF:\n",
    "\n",
    "1. Specify the argument \"add_custom_layers=True\" during conversion. This will automatically check for unsupported ops and insert a coreml custom layer message in place of that op. The message can be later edited, if required, to add/remove any parameters.            \n",
    "\n",
    "2. Specify the arguments \"add_custom_layers=True\" and \"custom_conversion_functions\" to the converter. The second argument is a dictionary, with keys that are either op types or op names and values are user-defined function handles. The functions receive TensorFlow [op](https://github.com/tensorflow/tensorflow/blob/51ef16057b4625e0a3e2943a9f1bbf856cf098ca/tensorflow/python/framework/ops.py#L3707) object and the CoreML neural network [builder object](https://github.com/apple/coremltools/blob/5b5b8190764ffe78110be6b4d0edbeebe0253a6e/coremltools/models/neural_network.py#L34) and give the user full control on how to handle the TF op and which layers to add to the CoreML graph. When the key is an op type, the function is called whenever op of that type is encountered while traversing the TF graph. Operation names as keys are useful for targeting specific ops. \n",
    "\n",
    "Lets now dive into the examples to make this process clear. \n",
    "\n",
    "First up, setting up some utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aseem/Aseem_env/env/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING:root:Keras version 2.1.5 detected. Last version known to be fully compatible of Keras is 2.1.3 .\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.python.tools.freeze_graph import freeze_graph\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tempfile\n",
    "import os\n",
    "import tfcoreml\n",
    "import coremltools\n",
    "from coremltools.proto import NeuralNetwork_pb2\n",
    "import netron # we use netron: https://github.com/lutzroeder/Netron for visualization. Comment out this line and all the calls to the \"_visualize\" method, if you do not want to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A utility function to freeze rhe graph. It will be used later\n",
    "def _simple_run_and_freeze(graph, output_name, frozen_model_file='', feed_dict={}):\n",
    "    \n",
    "    model_dir = tempfile.mkdtemp()\n",
    "    graph_def_file = os.path.join(model_dir, 'tf_graph.pbtxt')\n",
    "    checkpoint_file = os.path.join(model_dir, 'tf_model.ckpt')\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    with graph.as_default() as g:\n",
    "      saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session(graph = graph) as sess:\n",
    "      # initialize\n",
    "      sess.run(tf.global_variables_initializer())\n",
    "      # run the result\n",
    "      fetch = graph.get_operation_by_name(output_name).outputs[0]\n",
    "      tf_result = sess.run(fetch, feed_dict=feed_dict)\n",
    "      # save graph definition somewhere\n",
    "      tf.train.write_graph(sess.graph, model_dir, graph_def_file)\n",
    "      # save the weights\n",
    "      saver.save(sess, checkpoint_file)\n",
    "    \n",
    "    freeze_graph(input_graph=graph_def_file,\n",
    "                 input_saver=\"\",\n",
    "                 input_binary=False,\n",
    "                 input_checkpoint=checkpoint_file,\n",
    "                 output_node_names=output_name,\n",
    "                 restore_op_name=\"save/restore_all\",\n",
    "                 filename_tensor_name=\"save/Const:0\",\n",
    "                 output_graph=frozen_model_file,\n",
    "                 clear_devices=True,\n",
    "                 initializer_nodes=\"\")\n",
    "    \n",
    "    if os.path.exists(model_dir):\n",
    "        shutil.rmtree(model_dir)\n",
    "    \n",
    "    return tf_result\n",
    "\n",
    "# A utility function that takes an MLModel instance and prints info about Neural network layers inside.\n",
    "# It prints short info about all the NN layers and the full description of any custom layer found\n",
    "def _print_coreml_nn_layer_info(spec):\n",
    "    nn_layers = coremltools.models.utils._get_nn_layers(spec)\n",
    "    for i, layer in enumerate(nn_layers):\n",
    "        if layer.WhichOneof('layer') == 'custom':\n",
    "            print 'layer_id = ', i\n",
    "            print layer\n",
    "        else:\n",
    "            print('{}: layer type: ({}) , inputs: {}, outputs: {}'.\n",
    "              format(i,layer.WhichOneof('layer'), \", \".join([x for x in layer.input]), \", \".join([x for x in layer.output])))\n",
    "\n",
    "# We use \"netron\" for visualization. \n",
    "def _visualize(network_path, port_number):\n",
    "    \n",
    "    def visualize_using_netron(path, port_number):\n",
    "        netron.serve_file(path, browse = True, port=port_number)\n",
    "    \n",
    "    from threading import Thread\n",
    "    import time\n",
    "    \n",
    "    d = Thread(target = visualize_using_netron, args = (network_path, port_number,))\n",
    "    d.setDaemon(True)\n",
    "    d.start()\n",
    "    time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define the first TF graph. This one applies a dense layer and normalizes it. It uses the [\"Tile\"](https://www.tensorflow.org/versions/master/api_docs/python/tf/tile) op that CoreML does not support. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/09/hn9tml7d58nggsyxt54ymw5h0000gp/T/tmpp7o1Gk/tf_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/09/hn9tml7d58nggsyxt54ymw5h0000gp/T/tmpp7o1Gk/tf_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 2 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 2 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 2 variables to const ops.\n",
      "TF out:  UnitNorm/div (1, 10) 0.9999999\n"
     ]
    }
   ],
   "source": [
    "# define a TF graph: input -> Dense -> unit norm -> output\n",
    "graph = tf.Graph()\n",
    "with graph.as_default() as g:\n",
    "    inputs = tf.placeholder(tf.float32, shape=[None,8], name='input')\n",
    "    with slim.arg_scope([slim.fully_connected],\n",
    "          weights_initializer=tf.truncated_normal_initializer(0.0, 0.2),\n",
    "          weights_regularizer=slim.l2_regularizer(0.0005)):\n",
    "        y = slim.fully_connected(inputs, 10, scope='fc')\n",
    "        y = slim.unit_norm(y,dim=1)\n",
    "\n",
    "output_name = y.op.name\n",
    "X = np.random.rand(1,8)\n",
    "frozen_model_file = 'unit_norm_graph.pb'\n",
    "coreml_model_path = 'unit_norm_graph.mlmodel'\n",
    "out = _simple_run_and_freeze(graph, output_name, frozen_model_file, feed_dict={'input:0' : X})\n",
    "print 'TF out: ', output_name, out.shape, np.sum(out ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'unit_norm_graph.pb'\n",
      "Serving 'unit_norm_graph.pb' at http://localhost:8563\n"
     ]
    }
   ],
   "source": [
    "# visualize the frozen TF model\n",
    "_visualize(frozen_model_file, np.random.randint(8000, 9000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 10 tensors. Executing graph to determine shapes. \n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Unsupported Ops of type: Tile",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b8e959078f7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmlmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoreml_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minput_name_shape_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         output_feature_names=['UnitNorm/div:0'])\n\u001b[0m",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_tf_coreml_converter.pyc\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(tf_model_path, mlmodel_path, output_feature_names, input_name_shape_dict, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, predicted_probabilities_output, add_custom_layers, custom_conversion_functions)\u001b[0m\n\u001b[1;32m    550\u001b[0m       \u001b[0mpredicted_probabilities_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_probabilities_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m       \u001b[0madd_custom_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_custom_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m       custom_conversion_functions=custom_conversion_functions)\n\u001b[0m",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_tf_coreml_converter.pyc\u001b[0m in \u001b[0;36m_convert_pb_to_mlmodel\u001b[0;34m(tf_model_path, mlmodel_path, output_feature_names, input_name_shape_dict, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, predicted_probabilities_output, add_custom_layers, custom_conversion_functions)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \u001b[0munused_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffectively_constant_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_unused_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_feature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed_dict2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# return type: List[str], List[str]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madd_custom_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0m_check_unsupported_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_feature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffectively_constant_ops\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0munused_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_tf_coreml_converter.pyc\u001b[0m in \u001b[0;36m_check_unsupported_ops\u001b[0;34m(ops, output_feature_names, skip_ops)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munsupported_op_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m       raise NotImplementedError(\"Unsupported Ops of type: %s\" % (\n\u001b[0;32m--> 124\u001b[0;31m         ','.join(unsupported_op_types)))\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m def _convert_pb_to_mlmodel(tf_model_path,\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Unsupported Ops of type: Tile"
     ]
    }
   ],
   "source": [
    "# Try to convert it : this call should raise an error\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,8]},\n",
    "        output_feature_names=['UnitNorm/div:0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 10 tensors. Executing graph to determine shapes. \n",
      "1/26: Analysing op name: UnitNorm/concat/axis ( type:  Const )\n",
      "2/26: Analysing op name: UnitNorm/StridedSlice/end ( type:  Const )\n",
      "3/26: Analysing op name: UnitNorm/StridedSlice/begin ( type:  Const )\n",
      "4/26: Analysing op name: UnitNorm/ones_like/Const ( type:  Const )\n",
      "5/26: Analysing op name: UnitNorm/ones_like/Shape ( type:  Const )\n",
      "6/26: Analysing op name: UnitNorm/ones_like ( type:  Fill )\n",
      "7/26: Analysing op name: UnitNorm/ones ( type:  Const )\n",
      "8/26: Analysing op name: UnitNorm/add/x ( type:  Const )\n",
      "9/26: Analysing op name: UnitNorm/Sum/reduction_indices ( type:  Const )\n",
      "10/26: Analysing op name: fc/biases ( type:  Const )\n",
      "11/26: Analysing op name: fc/biases/read ( type:  Identity )\n",
      "12/26: Analysing op name: fc/weights ( type:  Const )\n",
      "13/26: Analysing op name: fc/weights/read ( type:  Identity )\n",
      "14/26: Analysing op name: input ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "15/26: Analysing op name: fc/MatMul ( type:  MatMul )\n",
      "16/26: Analysing op name: fc/BiasAdd ( type:  BiasAdd )\n",
      "17/26: Analysing op name: fc/Relu ( type:  Relu )\n",
      "18/26: Analysing op name: UnitNorm/Shape ( type:  Shape )\n",
      "19/26: Analysing op name: UnitNorm/StridedSlice ( type:  StridedSlice )\n",
      "20/26: Analysing op name: UnitNorm/concat ( type:  ConcatV2 )\n",
      "21/26: Analysing op name: UnitNorm/Square ( type:  Square )\n",
      "22/26: Analysing op name: UnitNorm/Sum ( type:  Sum )\n",
      "23/26: Analysing op name: UnitNorm/add ( type:  Add )\n",
      "24/26: Analysing op name: UnitNorm/Sqrt ( type:  Sqrt )\n",
      "25/26: Analysing op name: UnitNorm/Tile ( type:  Tile )\n",
      "Adding custom layer\n",
      "26/26: Analysing op name: UnitNorm/div ( type:  RealDiv )\n",
      "\n",
      " Core ML model generated. Saved at location: unit_norm_graph.mlmodel \n",
      "\n",
      "Core ML input(s): \n",
      " [name: \"input__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 8\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "Core ML output(s): \n",
      " [name: \"UnitNorm__div__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 10\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "\n",
      "\n",
      "Custom layers have been added to the CoreML model corresponding to the following ops in the TF graph: \n",
      "1/1: op type: Tile, op input names and shapes: [('UnitNorm/Sqrt:0', [1, 1]), ('UnitNorm/concat:0', [2])], op output names and shapes: [('UnitNorm/Tile:0', [1, 10])]\n"
     ]
    }
   ],
   "source": [
    "# we got an unsupported op error. Try again with custom Flag set to true\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,8]},\n",
    "        output_feature_names=['UnitNorm/div:0'],\n",
    "        add_custom_layers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the \"Tile\" op was made into a custom layer in the CoreML model. This op takes in two inputs, it recasts the first one into the shape given by the second input (by repetition). Here is the [documentation](https://www.tensorflow.org/versions/master/api_docs/python/tf/tile).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'unit_norm_graph.mlmodel'\n",
      "Serving 'unit_norm_graph.mlmodel' at http://localhost:8181\n"
     ]
    }
   ],
   "source": [
    "# visualize CoreML model\n",
    "_visualize(coreml_model_path, np.random.randint(8000, 9000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: As we can see in the visualization, the tensors whose values do not change based on the graph inputs (potentially they depend on the shape of the input, which needs to be fixed during conversion) are converted to \"load constant\" layers in the CoreML graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: layer type: (innerProduct) , inputs: input__0, outputs: fc/BiasAdd:0\n",
      "1: layer type: (activation) , inputs: fc/BiasAdd:0, outputs: fc/Relu:0\n",
      "2: layer type: (loadConstant) , inputs: , outputs: UnitNorm/StridedSlice:0\n",
      "3: layer type: (loadConstant) , inputs: , outputs: UnitNorm/ones:0\n",
      "4: layer type: (concat) , inputs: UnitNorm/ones:0, UnitNorm/StridedSlice:0, outputs: UnitNorm/concat:0\n",
      "5: layer type: (multiply) , inputs: fc/Relu:0, fc/Relu:0, outputs: UnitNorm/Square:0\n",
      "6: layer type: (reduce) , inputs: UnitNorm/Square:0, outputs: UnitNorm/Sum:0\n",
      "7: layer type: (add) , inputs: UnitNorm/Sum:0, outputs: UnitNorm/add:0\n",
      "8: layer type: (unary) , inputs: UnitNorm/add:0, outputs: UnitNorm/Sqrt:0\n",
      "layer_id =  9\n",
      "name: \"UnitNorm/Tile\"\n",
      "input: \"UnitNorm/Sqrt:0\"\n",
      "input: \"UnitNorm/concat:0\"\n",
      "output: \"UnitNorm/Tile:0\"\n",
      "custom {\n",
      "  className: \"Tile\"\n",
      "  description: \"Custom layer that corresponds to the TensorFlow op Tile\"\n",
      "}\n",
      "\n",
      "10: layer type: (unary) , inputs: UnitNorm/Tile:0, outputs: inversed_UnitNorm/Tile:0_UnitNorm/div:0\n",
      "11: layer type: (multiply) , inputs: fc/Relu:0, inversed_UnitNorm/Tile:0_UnitNorm/div:0, outputs: UnitNorm__div__0\n"
     ]
    }
   ],
   "source": [
    "# inspect the CoreML model\n",
    "spec = coreml_model.get_spec()\n",
    "_print_coreml_nn_layer_info(spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"ClassName\" is an important message: this is the name of the swift/objective-c class that needs to implemented in the Xcode app and will contain the actual code for running the layer.  \n",
    "The \"tile\" op does not have any parameters, so there is no need to edit generated the coreml specification. Lets now convert a TF graph with the op [\"TopKV2\"](https://www.tensorflow.org/api_docs/python/tf/nn/top_k) that has parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/09/hn9tml7d58nggsyxt54ymw5h0000gp/T/tmpEm066N/tf_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/09/hn9tml7d58nggsyxt54ymw5h0000gp/T/tmpEm066N/tf_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 2 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 2 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 2 variables to const ops.\n",
      "TF out:  output (1, 3) [[0.09352796 0.12875162 0.1025504 ]]\n"
     ]
    }
   ],
   "source": [
    "# define a TF graph: input -> Dense -> softmax -> top_k -> output\n",
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default() as g:\n",
    "    x = tf.placeholder(tf.float32, shape=[None,8], name=\"input\")\n",
    "    y = tf.layers.dense(inputs=x, units=12, activation=tf.nn.relu)\n",
    "    y = tf.nn.softmax(y, axis=1)\n",
    "    y = tf.nn.top_k(y, k=3, sorted = False, name='output')\n",
    "    \n",
    "output_name = 'output'    \n",
    "X = np.random.rand(1,8)\n",
    "frozen_model_file = 'topk_graph.pb'\n",
    "coreml_model_path = 'topk_graph.mlmodel'\n",
    "out = _simple_run_and_freeze(graph, output_name, frozen_model_file, feed_dict={'input:0' : X})\n",
    "print 'TF out: ', output_name, out.shape, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'topk_graph.pb'\n",
      "Serving 'topk_graph.pb' at http://localhost:8202\n"
     ]
    }
   ],
   "source": [
    "# visualize the frozen TF model\n",
    "_visualize(frozen_model_file, np.random.randint(8000, 9000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 7 tensors. Executing graph to determine shapes. \n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Unsupported Ops of type: TopKV2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2017099fe858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmlmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoreml_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minput_name_shape_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         output_feature_names=['output:0'])\n\u001b[0m",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_tf_coreml_converter.pyc\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(tf_model_path, mlmodel_path, output_feature_names, input_name_shape_dict, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, predicted_probabilities_output, add_custom_layers, custom_conversion_functions)\u001b[0m\n\u001b[1;32m    550\u001b[0m       \u001b[0mpredicted_probabilities_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_probabilities_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m       \u001b[0madd_custom_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_custom_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m       custom_conversion_functions=custom_conversion_functions)\n\u001b[0m",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_tf_coreml_converter.pyc\u001b[0m in \u001b[0;36m_convert_pb_to_mlmodel\u001b[0;34m(tf_model_path, mlmodel_path, output_feature_names, input_name_shape_dict, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, predicted_probabilities_output, add_custom_layers, custom_conversion_functions)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \u001b[0munused_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffectively_constant_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_unused_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_feature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed_dict2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# return type: List[str], List[str]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madd_custom_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0m_check_unsupported_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_feature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffectively_constant_ops\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0munused_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_tf_coreml_converter.pyc\u001b[0m in \u001b[0;36m_check_unsupported_ops\u001b[0;34m(ops, output_feature_names, skip_ops)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munsupported_op_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m       raise NotImplementedError(\"Unsupported Ops of type: %s\" % (\n\u001b[0;32m--> 124\u001b[0;31m         ','.join(unsupported_op_types)))\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m def _convert_pb_to_mlmodel(tf_model_path,\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Unsupported Ops of type: TopKV2"
     ]
    }
   ],
   "source": [
    "# Try to convert it : this call should raise an error\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,8]},\n",
    "        output_feature_names=['output:0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 7 tensors. Executing graph to determine shapes. \n",
      "1/11: Analysing op name: output/k ( type:  Const )\n",
      "2/11: Analysing op name: dense/bias ( type:  Const )\n",
      "3/11: Analysing op name: dense/bias/read ( type:  Identity )\n",
      "4/11: Analysing op name: dense/kernel ( type:  Const )\n",
      "5/11: Analysing op name: dense/kernel/read ( type:  Identity )\n",
      "6/11: Analysing op name: input ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "7/11: Analysing op name: dense/MatMul ( type:  MatMul )\n",
      "8/11: Analysing op name: dense/BiasAdd ( type:  BiasAdd )\n",
      "9/11: Analysing op name: dense/Relu ( type:  Relu )\n",
      "10/11: Analysing op name: Softmax ( type:  Softmax )\n",
      "11/11: Analysing op name: output ( type:  TopKV2 )\n",
      "Adding custom layer\n",
      "\n",
      " Core ML model generated. Saved at location: topk_graph.mlmodel \n",
      "\n",
      "Core ML input(s): \n",
      " [name: \"input__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 8\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "Core ML output(s): \n",
      " [name: \"output__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 3\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "\n",
      "\n",
      "Custom layers have been added to the CoreML model corresponding to the following ops in the TF graph: \n",
      "1/1: op type: TopKV2, op input names and shapes: [('Softmax:0', [1, 12]), ('output/k:0', [])], op output names and shapes: [('output:0', [1, 3]), ('output:1', [1, 3])]\n"
     ]
    }
   ],
   "source": [
    "# we got an unsupported op error. Try again with custom Flag set to true\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,8]},\n",
    "        output_feature_names=['output:0'],\n",
    "        add_custom_layers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: layer type: (innerProduct) , inputs: input__0, outputs: dense/BiasAdd:0\n",
      "1: layer type: (activation) , inputs: dense/BiasAdd:0, outputs: dense/Relu:0\n",
      "2: layer type: (softmax) , inputs: dense/Relu:0, outputs: Softmax:0\n",
      "layer_id =  3\n",
      "name: \"output\"\n",
      "input: \"Softmax:0\"\n",
      "input: \"output/k:0\"\n",
      "output: \"output__0\"\n",
      "output: \"output:1\"\n",
      "custom {\n",
      "  className: \"TopKV2\"\n",
      "  description: \"Custom layer that corresponds to the TensorFlow op TopKV2\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inspect the CoreML model\n",
    "spec = coreml_model.get_spec()\n",
    "_print_coreml_nn_layer_info(spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top_k](https://www.tensorflow.org/api_docs/python/tf/nn/top_k) operation has two parameters: 'k' and 'sorted'. In the TF graph, the former is received as an additional input by the op and the latter is an op attribute. \n",
    "Let us modify the MLModel spec directly to add these two parameters to this layer. We need to know a little bit about the custom layer's [proto message](https://github.com/apple/coremltools/blob/5b5b8190764ffe78110be6b4d0edbeebe0253a6e/mlmodel/format/NeuralNetwork.proto#L2280) structure to be able to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: layer type: (innerProduct) , inputs: input__0, outputs: dense/BiasAdd:0\n",
      "1: layer type: (activation) , inputs: dense/BiasAdd:0, outputs: dense/Relu:0\n",
      "2: layer type: (softmax) , inputs: dense/Relu:0, outputs: Softmax:0\n",
      "layer_id =  3\n",
      "name: \"output\"\n",
      "input: \"Softmax:0\"\n",
      "output: \"output__0\"\n",
      "custom {\n",
      "  className: \"TopKV2\"\n",
      "  parameters {\n",
      "    key: \"k\"\n",
      "    value {\n",
      "      intValue: 3\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"sorted\"\n",
      "    value {\n",
      "      boolValue: false\n",
      "    }\n",
      "  }\n",
      "  description: \"Custom layer that corresponds to the TensorFlow op TopKV2\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_layers = coremltools.models.utils._get_nn_layers(spec) # get all the layers as a list\n",
    "del nn_layers[3].input[1] # delete the second input: its just the value of k\n",
    "del nn_layers[3].output[1] # delete the second output\n",
    "nn_layers[3].custom.parameters[\"k\"].intValue = 3\n",
    "nn_layers[3].custom.parameters[\"sorted\"].boolValue = False\n",
    "_print_coreml_nn_layer_info(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the spec back out\n",
    "coremltools.models.utils.save_spec(spec, coreml_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'topk_graph.mlmodel'\n",
      "Serving 'topk_graph.mlmodel' at http://localhost:8950\n"
     ]
    }
   ],
   "source": [
    "# visualize CoreML model\n",
    "_visualize(coreml_model_path, np.random.randint(8000, 9000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an alternative way to do the same thing using the \"custom_conversion_functions\" argument: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 7 tensors. Executing graph to determine shapes. \n",
      "1/11: Analysing op name: output/k ( type:  Const )\n",
      "2/11: Analysing op name: dense/bias ( type:  Const )\n",
      "3/11: Analysing op name: dense/bias/read ( type:  Identity )\n",
      "4/11: Analysing op name: dense/kernel ( type:  Const )\n",
      "5/11: Analysing op name: dense/kernel/read ( type:  Identity )\n",
      "6/11: Analysing op name: input ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "7/11: Analysing op name: dense/MatMul ( type:  MatMul )\n",
      "8/11: Analysing op name: dense/BiasAdd ( type:  BiasAdd )\n",
      "9/11: Analysing op name: dense/Relu ( type:  Relu )\n",
      "10/11: Analysing op name: Softmax ( type:  Softmax )\n",
      "11/11: Analysing op name: output ( type:  TopKV2 )\n",
      "Adding custom layer\n",
      "\n",
      " Core ML model generated. Saved at location: topk_graph.mlmodel \n",
      "\n",
      "Core ML input(s): \n",
      " [name: \"input__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 8\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "Core ML output(s): \n",
      " [name: \"output__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 3\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "\n",
      "\n",
      "Custom layers have been added to the CoreML model corresponding to the following ops in the TF graph: \n",
      "1/1: op type: TopKV2, op input names and shapes: [('Softmax:0', [1, 12]), ('output/k:0', [])], op output names and shapes: [('output:0', [1, 3]), ('output:1', [1, 3])]\n",
      "\n",
      " \n",
      " ML Model layers info: \n",
      "\n",
      "0: layer type: (innerProduct) , inputs: input__0, outputs: dense/BiasAdd:0\n",
      "1: layer type: (activation) , inputs: dense/BiasAdd:0, outputs: dense/Relu:0\n",
      "2: layer type: (softmax) , inputs: dense/Relu:0, outputs: Softmax:0\n",
      "layer_id =  3\n",
      "name: \"output\"\n",
      "input: \"Softmax:0\"\n",
      "output: \"output__0\"\n",
      "custom {\n",
      "  className: \"Top_K\"\n",
      "  parameters {\n",
      "    key: \"k\"\n",
      "    value {\n",
      "      intValue: 3\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"sorted\"\n",
      "    value {\n",
      "      boolValue: false\n",
      "    }\n",
      "  }\n",
      "  description: \"Custom layer that corresponds to the top_k TF op\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _convert_topk(**kwargs):\n",
    "    tf_op = kwargs[\"op\"]\n",
    "    coreml_nn_builder = kwargs[\"nn_builder\"]\n",
    "    constant_inputs = kwargs[\"constant_inputs\"]\n",
    "    \n",
    "    params = NeuralNetwork_pb2.CustomLayerParams()\n",
    "    params.className = 'Top_K'\n",
    "    params.description = \"Custom layer that corresponds to the top_k TF op\"\n",
    "    params.parameters[\"sorted\"].boolValue = tf_op.get_attr('sorted')\n",
    "    # get the value of k\n",
    "    k = constant_inputs.get(tf_op.inputs[1].name, 3)\n",
    "    params.parameters[\"k\"].intValue = k\n",
    "    coreml_nn_builder.add_custom(name=tf_op.name,\n",
    "                                input_names=[tf_op.inputs[0].name],\n",
    "                                output_names=[tf_op.outputs[0].name],\n",
    "                                custom_proto_spec=params)\n",
    "\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,8]},\n",
    "        output_feature_names=['output:0'],\n",
    "        add_custom_layers=True,\n",
    "        custom_conversion_functions={'TopKV2': _convert_topk})\n",
    "\n",
    "print(\"\\n \\n ML Model layers info: \\n\")\n",
    "# inspect the CoreML model: this should be same as the one we got above\n",
    "spec = coreml_model.get_spec()\n",
    "_print_coreml_nn_layer_info(spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lets move on to the third and the final example. Now we will encounter an op that is supported but it errors out due to an unsupported coniguration. It is the [Slice](https://www.tensorflow.org/versions/master/api_docs/python/tf/slice) op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/09/hn9tml7d58nggsyxt54ymw5h0000gp/T/tmpLTFwVp/tf_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/09/hn9tml7d58nggsyxt54ymw5h0000gp/T/tmpLTFwVp/tf_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 1 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 1 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 1 variables to const ops.\n",
      "TF out:  output (1, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# define a TF graph: input -> conv -> slice -> output\n",
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default() as g:\n",
    "    x = tf.placeholder(tf.float32, shape=[None,10,10,3], name=\"input\")\n",
    "    W = tf.Variable(tf.truncated_normal([1,1,3,5], stddev=0.1))\n",
    "    y = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    y = tf.slice(y, begin=[0,1,1,1], size=[1,2,2,2], name='output')\n",
    "    \n",
    "output_name = 'output'    \n",
    "X = np.random.rand(1,10,10,3)\n",
    "frozen_model_file = 'slice_graph.pb'\n",
    "coreml_model_path = 'slice_graph.mlmodel'\n",
    "out = _simple_run_and_freeze(graph, output_name, frozen_model_file, feed_dict={'input:0' : X})\n",
    "print 'TF out: ', output_name, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'slice_graph.pb'\n",
      "Serving 'slice_graph.pb' at http://localhost:8383\n"
     ]
    }
   ],
   "source": [
    "# visualize the frozen TF model\n",
    "_visualize(frozen_model_file, np.random.randint(8000, 9000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 2 tensors. Executing graph to determine shapes. \n",
      "Automatic shape interpretation succeeded for input blob input:0\n",
      "1/7: Analysing op name: output/size ( type:  Const )\n",
      "2/7: Analysing op name: output/begin ( type:  Const )\n",
      "3/7: Analysing op name: Variable ( type:  Const )\n",
      "4/7: Analysing op name: Variable/read ( type:  Identity )\n",
      "5/7: Analysing op name: input ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "6/7: Analysing op name: Conv2D ( type:  Conv2D )\n",
      "7/7: Analysing op name: output ( type:  Slice )\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Slice case not handled (input shape: [1, 10, 10, 5], output shape: [1, 2, 2, 2])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-35c914f51c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmlmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoreml_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minput_name_shape_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         output_feature_names=['output:0'])\n\u001b[0m",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_tf_coreml_converter.pyc\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(tf_model_path, mlmodel_path, output_feature_names, input_name_shape_dict, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, predicted_probabilities_output, add_custom_layers, custom_conversion_functions)\u001b[0m\n\u001b[1;32m    550\u001b[0m       \u001b[0mpredicted_probabilities_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_probabilities_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m       \u001b[0madd_custom_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_custom_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m       custom_conversion_functions=custom_conversion_functions)\n\u001b[0m",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_tf_coreml_converter.pyc\u001b[0m in \u001b[0;36m_convert_pb_to_mlmodel\u001b[0;34m(tf_model_path, mlmodel_path, output_feature_names, input_name_shape_dict, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, predicted_probabilities_output, add_custom_layers, custom_conversion_functions)\u001b[0m\n\u001b[1;32m    313\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_custom_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_custom_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_conversion_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_conversion_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m   \u001b[0mconvert_ops_to_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m   \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_ops_to_layers.pyc\u001b[0m in \u001b[0;36mconvert_ops_to_layers\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtranslation_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mtranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m       \u001b[0mconnect_skipped_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_layers.pyc\u001b[0m in \u001b[0;36mslice\u001b[0;34m(op, context)\u001b[0m\n\u001b[1;32m   1189\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m     raise NotImplementedError('Slice case not handled '\n\u001b[0;32m-> 1191\u001b[0;31m             '(input shape: %s, output shape: %s)'%(str(input_shape), str(output_shape)))\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Slice case not handled (input shape: [1, 10, 10, 5], output shape: [1, 2, 2, 2])"
     ]
    }
   ],
   "source": [
    "# Try to convert it : this call should raise an error\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,10,10,3]},\n",
    "        output_feature_names=['output:0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fails, so we provide a custom layer function. Note that this time, the key in the dictionary provided via  \"custom_conversion_functions\" should be same as the op name (\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_slice(**kwargs):\n",
    "    tf_op = kwargs[\"op\"]\n",
    "    coreml_nn_builder = kwargs[\"nn_builder\"]\n",
    "    constant_inputs = kwargs[\"constant_inputs\"]\n",
    "    \n",
    "    params = NeuralNetwork_pb2.CustomLayerParams()\n",
    "    params.className = 'Slice'\n",
    "    params.description = \"Custom layer that corresponds to the slice TF op\"\n",
    "    # get the value of begin\n",
    "    begin = constant_inputs.get(tf_op.inputs[1].name, [0,0,0,0])\n",
    "    size = constant_inputs.get(tf_op.inputs[2].name, [0,0,0,0])\n",
    "    # add begin and size as two repeated weight fields\n",
    "    begin_as_weights = params.weights.add()\n",
    "    begin_as_weights.floatValue.extend(map(float, begin))\n",
    "    size_as_weights = params.weights.add()\n",
    "    size_as_weights.floatValue.extend(map(float, size))\n",
    "    coreml_nn_builder.add_custom(name=tf_op.name,\n",
    "                                input_names=[tf_op.inputs[0].name],\n",
    "                                output_names=[tf_op.outputs[0].name],\n",
    "                                custom_proto_spec=params)\n",
    "\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,10,10,3]},\n",
    "        output_feature_names=['output:0'],\n",
    "        add_custom_layers=True,\n",
    "        custom_conversion_functions={'output': _convert_slice}) # dictionary has op name as the key\n",
    "\n",
    "print(\"\\n \\n ML Model layers info: \\n\")\n",
    "# inspect the CoreML model: this should be same as the one we got above\n",
    "spec = coreml_model.get_spec()\n",
    "_print_coreml_nn_layer_info(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize CoreML model\n",
    "_visualize(coreml_model_path, np.random.randint(8000, 9000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
